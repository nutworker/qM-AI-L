{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nutworker/qM-AI-L/blob/L_test/email-subject/model-tuning/AESLC_tuning_v7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repository_url = 'https://github.com/nutworker/qM-AI-L'\n",
        "!git clone {repository_url}"
      ],
      "metadata": {
        "id": "n0UfO9kv4-nq",
        "outputId": "59904334-76b0-4a85-8d18-9f68a465d3ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qM-AI-L'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 111 (delta 45), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (111/111), 7.81 MiB | 3.25 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ID0koCUtX33Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b87d68f5-7e46-4a4e-b647-edddf74f5c73",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.0.0->evaluate)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Collecting requests>=2.19.0 (from evaluate)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 pyarrow-17.0.0 requests-2.32.3 xxhash-3.4.1\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e01afcab04baed853daaeee3f4980d11ab70c974c3b0240fac7a2285e5b971d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.32.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.10.1 sacrebleu-2.4.2\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install rouge-score # Installing rouge-score library (https://pypi.org/project/rouge-score/)\n",
        "\n",
        "# !pip install accelerate -U\n",
        "\n",
        "!pip install transformers[torch]\n",
        "!pip install sacrebleu\n",
        "\n",
        "!pip install datasets nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import pandas as pd # Data Handling\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import seaborn as sns\n",
        "\n",
        "from datasets import load_metric\n",
        "from datasets import Dataset\n",
        "import evaluate\n",
        "\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "xuOoOaSEDLqg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration      # BERT Tokenizer and architecture\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments         # These will help us to fine-tune our model\n",
        "from transformers import pipeline                                         # Pipeline\n",
        "from transformers import DataCollatorForSeq2Seq                           # DataCollator to batch the data\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "tbXvEcauCHyq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "import sacrebleu\n",
        "from nltk.translate.meteor_score import meteor_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7T6r-6fLsBo",
        "outputId": "d403fb37-a8c2-4805-de0b-a9edc60d63dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset**"
      ],
      "metadata": {
        "id": "As3cC5xSngQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = pd.read_csv('/content/qM-AI-L/email-subject/model-tuning/train_emails.csv')"
      ],
      "metadata": {
        "id": "4nBEREYUQPjQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df"
      ],
      "metadata": {
        "id": "L9skosJrQc0t",
        "outputId": "0dd1c764-8856-4809-d019-ad8bc5236933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    source                                               body  \\\n",
              "0         allen-p_inbox_20  Greg/Phillip,  Attached is the Grande Communic...   \n",
              "1         allen-p_inbox_28  Phillip & Keith  Attached is the first draw re...   \n",
              "2         allen-p_inbox_63  Your Internet Banking accounts are now setup a...   \n",
              "3         allen-p_inbox_64  To our IBS Customers that are still hanging in...   \n",
              "4         allen-p_inbox_65  Phillip Good Morning!\\nI hope you had a wonder...   \n",
              "...                    ...                                                ...   \n",
              "14431  zufferli-j_inbox_43  This email is acknowledgement from the Power P...   \n",
              "14432  zufferli-j_inbox_44  This email is acknowledgement from the Power P...   \n",
              "14433  zufferli-j_inbox_46  John,  Further to the voice message that I lef...   \n",
              "14434   zufferli-j_inbox_8  Make sure that all curves are downloaded by th...   \n",
              "14435   zufferli-j_inbox_9  John:  Do you need Accumap day one?\\nCarmen sa...   \n",
              "\n",
              "                       subject  ann0  ann1  ann2  body_wcount  subj_wcount  \\\n",
              "0            Service Agreement   NaN   NaN   NaN           65            2   \n",
              "1               Bishops Corner   NaN   NaN   NaN          145            2   \n",
              "2             Internet Banking   NaN   NaN   NaN          250            2   \n",
              "3             Internet Banking   NaN   NaN   NaN          458            2   \n",
              "4      SMEs for expert stories   NaN   NaN   NaN           68            4   \n",
              "...                        ...   ...   ...   ...          ...          ...   \n",
              "14431               Power Pool   NaN   NaN   NaN          227            2   \n",
              "14432    Power Pool of Alberta   NaN   NaN   NaN          277            4   \n",
              "14433           Enron Security   NaN   NaN   NaN          148            2   \n",
              "14434        Simulation Curves   NaN   NaN   NaN           66            2   \n",
              "14435              IHS Accumap   NaN   NaN   NaN           35            2   \n",
              "\n",
              "                                          cleaned_emails  \n",
              "0      gregphillip attached is the grande communicati...  \n",
              "1      phillip keith attached is the first draw reque...  \n",
              "2      your internet banking accounts are now setup a...  \n",
              "3      to our ibs customers that are still hanging in...  \n",
              "4      phillip good morning i hope you had a wonderfu...  \n",
              "...                                                  ...  \n",
              "14431  this email is acknowledgement from the power p...  \n",
              "14432  this email is acknowledgement from the power p...  \n",
              "14433  john further to the voice message that i left ...  \n",
              "14434  make sure that all curves are downloaded by th...  \n",
              "14435  john do you need accumap day one carmen said t...  \n",
              "\n",
              "[14436 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c091778a-c620-46f4-a30b-2d98ff888af3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>body</th>\n",
              "      <th>subject</th>\n",
              "      <th>ann0</th>\n",
              "      <th>ann1</th>\n",
              "      <th>ann2</th>\n",
              "      <th>body_wcount</th>\n",
              "      <th>subj_wcount</th>\n",
              "      <th>cleaned_emails</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p_inbox_20</td>\n",
              "      <td>Greg/Phillip,  Attached is the Grande Communic...</td>\n",
              "      <td>Service Agreement</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65</td>\n",
              "      <td>2</td>\n",
              "      <td>gregphillip attached is the grande communicati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p_inbox_28</td>\n",
              "      <td>Phillip &amp; Keith  Attached is the first draw re...</td>\n",
              "      <td>Bishops Corner</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>145</td>\n",
              "      <td>2</td>\n",
              "      <td>phillip keith attached is the first draw reque...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allen-p_inbox_63</td>\n",
              "      <td>Your Internet Banking accounts are now setup a...</td>\n",
              "      <td>Internet Banking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>250</td>\n",
              "      <td>2</td>\n",
              "      <td>your internet banking accounts are now setup a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>allen-p_inbox_64</td>\n",
              "      <td>To our IBS Customers that are still hanging in...</td>\n",
              "      <td>Internet Banking</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>458</td>\n",
              "      <td>2</td>\n",
              "      <td>to our ibs customers that are still hanging in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>allen-p_inbox_65</td>\n",
              "      <td>Phillip Good Morning!\\nI hope you had a wonder...</td>\n",
              "      <td>SMEs for expert stories</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68</td>\n",
              "      <td>4</td>\n",
              "      <td>phillip good morning i hope you had a wonderfu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14431</th>\n",
              "      <td>zufferli-j_inbox_43</td>\n",
              "      <td>This email is acknowledgement from the Power P...</td>\n",
              "      <td>Power Pool</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>227</td>\n",
              "      <td>2</td>\n",
              "      <td>this email is acknowledgement from the power p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14432</th>\n",
              "      <td>zufferli-j_inbox_44</td>\n",
              "      <td>This email is acknowledgement from the Power P...</td>\n",
              "      <td>Power Pool of Alberta</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>277</td>\n",
              "      <td>4</td>\n",
              "      <td>this email is acknowledgement from the power p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14433</th>\n",
              "      <td>zufferli-j_inbox_46</td>\n",
              "      <td>John,  Further to the voice message that I lef...</td>\n",
              "      <td>Enron Security</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>148</td>\n",
              "      <td>2</td>\n",
              "      <td>john further to the voice message that i left ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14434</th>\n",
              "      <td>zufferli-j_inbox_8</td>\n",
              "      <td>Make sure that all curves are downloaded by th...</td>\n",
              "      <td>Simulation Curves</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>66</td>\n",
              "      <td>2</td>\n",
              "      <td>make sure that all curves are downloaded by th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14435</th>\n",
              "      <td>zufferli-j_inbox_9</td>\n",
              "      <td>John:  Do you need Accumap day one?\\nCarmen sa...</td>\n",
              "      <td>IHS Accumap</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35</td>\n",
              "      <td>2</td>\n",
              "      <td>john do you need accumap day one carmen said t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14436 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c091778a-c620-46f4-a30b-2d98ff888af3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c091778a-c620-46f4-a30b-2d98ff888af3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c091778a-c620-46f4-a30b-2d98ff888af3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c71b3279-d242-43a4-955f-a54ae9e791a4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c71b3279-d242-43a4-955f-a54ae9e791a4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c71b3279-d242-43a4-955f-a54ae9e791a4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b0c82296-6d3a-4087-82de-2ac1392d2e18\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b0c82296-6d3a-4087-82de-2ac1392d2e18 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset_df",
              "summary": "{\n  \"name\": \"dataset_df\",\n  \"rows\": 14436,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14436,\n        \"samples\": [\n          \"sanders-r_sent_2329\",\n          \"buy-r_inbox_344\",\n          \"dorland-c_sent_301\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13523,\n        \"samples\": [\n          \"Sara: Here are drafts of the Certificates and Sight Drafts for Niagara Mohawk, El Paso electric, LG&E Energy Marketing and Energy Production Corp. (just in case it wasn't renewed).\\nI have put together files for each of these that include copies of the LC, the underlying trading docs and any correspondence that has been sent.\\nExcept for Niagara Mohawk which requires copies of the invoices and that the certificate be on \\\"letterhead\\\" there don't appear to be any other special requirements.\\nLeslie Reeves will be faxing the invoices to us.\\nI will be in tomorrow until around 11.\\nThanks for your help on this.\\nAll of these docs are in a file called Enron Restructuring.\",\n          \"Good afternoon,  When you get a chance, please let me know if you would like for me to order you a 2002 calendar.\\nIf so, which kind?\\nYou may want more than one type.\\nJust let me know and I will be more than happy to order what you want.\\nThanks!\",\n          \"Hey Hunter, A quick update.\\nKevin Brady is up to speed on working with Colin and Chris on consolidating critical and noncritical notices for all the regions.\\nI have also passed on the idea of an operations page on the website to the other logistics managers and the central desk schedulers to get their ideas and insights on how to make this page beneficial to both the traders and schedulers.\\nA couple of ideas that have already been passed my way are:  \\t1) Incorporating the Gas Daily and Index historicals against production/storage by pipe so that we could project cash outs (Mark Schrab) \\t2) A transportation rate matrix on the web site (Cora Pendergrass) \\t3) Enron operations personnel contact page with phone numbers and pictures.\\nMuch like the weather guys.\\nI laughed at first but Victor LaMadrid   \\t\\twhom suggested this said that the East Desk Traders don't even know all of his schedulers.\\n4) An easy access to the pipelines meters and dunns numbers.\\n(Kevin Brady) \\t5) Morning sheets updated with contract, constraint, and imbalance information from Sitara and Unify (Victor LaMadrid)  I have asked Kevin to consolidate all the ideas and then we can get together and decide which ones you want to place into production.\\nLisa\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12032,\n        \"samples\": [\n          \"OMLX Application\",\n          \"Draft OF CA\",\n          \"Wharton trip\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body_wcount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 148,\n        \"min\": 25,\n        \"max\": 3136,\n        \"num_unique_values\": 683,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subj_wcount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 15,\n        \"num_unique_values\": 15,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_emails\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13498,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Train Split**"
      ],
      "metadata": {
        "id": "L6sRPzc6oU02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_df = dataset_df.sample(frac=0.4, random_state=42)\n",
        "subset_df.shape"
      ],
      "metadata": {
        "id": "1lnDOKzv4QZb",
        "outputId": "e351351d-d8d6-484e-96a9-92575efb9263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5774, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_df, Test_df = train_test_split(subset_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "guCjiJJyRLzM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_df.shape, Test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHgDx01BreHk",
        "outputId": "797638fa-e923-4071-c0e0-9be182a60ba9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4619, 9), (1155, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yWGKFsujF8B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_dataset = Dataset.from_pandas(Train_df)\n",
        "Test_dataset = Dataset.from_pandas(Test_df)"
      ],
      "metadata": {
        "id": "ZHaFrU6-oYQ5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_dataset, Test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfLahVPWoa1X",
        "outputId": "81608088-2e76-4719-abf7-cef02c33f88c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['source', 'body', 'subject', 'ann0', 'ann1', 'ann2', 'body_wcount', 'subj_wcount', 'cleaned_emails', '__index_level_0__'],\n",
              "     num_rows: 4619\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['source', 'body', 'subject', 'ann0', 'ann1', 'ann2', 'body_wcount', 'subj_wcount', 'cleaned_emails', '__index_level_0__'],\n",
              "     num_rows: 1155\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a subset of Dataset**"
      ],
      "metadata": {
        "id": "ofsPKKg_nxk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #create a subset of dataset\n",
        "# train_dataset = Train_dataset.filter(lambda example, index: index % 2 == 0, with_indices=True)\n",
        "# test_dataset = Test_dataset.filter(lambda example, index: index % 2 == 0, with_indices=True)\n",
        "\n",
        "Train_dataset.shape, Test_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iDTgW2UtjIT",
        "outputId": "c59cc635-3cdc-413b-8f0a-c89df2c835c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4619, 10), (1155, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_dataset['cleaned_emails'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "nghT9hdrfoYJ",
        "outputId": "1dd610bb-ebe3-4cbc-c0c1-fc034bd0ad69"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this follows up on my voicemail to you of just a few minutes ago. i reviewed a voicemail from theresa bushman this morning about the timing on the new mariner matter that mariner for which mariner would like to retain fj. she has spoken with scott josie apparently one of our business people and has been advised that the december 27 closing is critical due to market conditions. theresa also believes that the december 27 date will be aggressive even for fj given the late date. theresa please let me know if i have mischaracterized what you said. i see two options 1. if you agree with me that we cant sign the letter as is i do my best to get an acceptable letter negotiated with uriel dutton today. if i cant mariner retains someone else today. frankly i am not optimistic about getting an acceptable letter from fj based on where fj started. 2. if you believe that we need to go ahead and get the best deal we can from fj under the circumstances i will do my best to get that done by noon or so and if fj doesnt budge we may have to sign the letter as is. caveat i dont know if dutton is in the office this week so he and i may not be able to communicate quickly. also if we redraft a letter we will probably not have time to get comments back from all the other interested enron attorneys. i would also suggest telling kelly zelacovitz mariners gc this morning what our game plan is and if it is option one have her go ahead and contact her backup choices of law firms start running conflicts checks etc. and have them be ready to hit the ground running. if there is anyone else i need to send this email to please let me know. i am in all day today please let me know what you want me to do. britt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the pre-trained FLAN-T5 models and its tokenizer directly from HuggingFace. FLAN-T5 was released in the paper Scaling Instruction-Finetuned Language Models - it is an enhanced version of T5 that has been finetuned in a mixture of tasks. Setting torch_dtype=torch.bfloat16 specifies the memory type to be used by this model.**"
      ],
      "metadata": {
        "id": "qUwUyn2SowRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get size of models\n",
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"Trainable model parameters: {trainable_model_params}\\nAll model parameters: {all_model_params}\\nPercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n"
      ],
      "metadata": {
        "id": "0fsHEX6Bm3an"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Flan T5 Base Model**"
      ],
      "metadata": {
        "id": "GKeNgh0NpSaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model_name = \"google/flan-t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# Freeze the first 6 layers of the encoder and decoder\n",
        "for param in model.encoder.block[:6].parameters(): # Use 'block' instead of 'layers'\n",
        "    param.requires_grad = False\n",
        "for param in model.decoder.block[:6].parameters(): # Use 'block' instead of 'layers'\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"For Model : FLAN-T5-Base \\n\",print_number_of_trainable_model_parameters(model))"
      ],
      "metadata": {
        "id": "Xkz4NmaW0KPZ",
        "outputId": "a1467d7a-1e88-497b-bc3d-d4d6a7e2ab5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Model : FLAN-T5-Base \n",
            " Trainable model parameters: 148463616\n",
            "All model parameters: 247577856\n",
            "Percentage of trainable model parameters: 59.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"For Model : FLAN-T5-Base \\n\",print_number_of_trainable_model_parameters(model))"
      ],
      "metadata": {
        "id": "qhDSbG6W2BZN",
        "outputId": "85d6c650-0747-4dd8-ac81-c9763af848cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Model : FLAN-T5-Base \n",
            " Trainable model parameters: 0\n",
            "All model parameters: 247577856\n",
            "Percentage of trainable model parameters: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    inputs = [\"generate subject line: \" + example for example in examples[\"body\"]] # Access the 'body' column\n",
        "    targets = [example for example in examples[\"subject\"]] # Access the 'subject' column\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "2qUVhlTf07dU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_dataset = Train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_eval_dataset = Test_dataset.map(tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "UPg_4Oau1Cem",
        "outputId": "2694d1db-58ff-4792-fd1e-686c9e942b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "30d4a769c5544445bc13b613ba4cdee4",
            "385784146b014ea2821e9c9a3320ba10",
            "211e0379921d43458478b337eb094fc8",
            "d3570989cfbf4fce801c7447d73d0bfc",
            "277b89aaf7e54b4e98cc45bc462cb785",
            "de7042c773dd40b9bf418c1eb3819d10",
            "cca7d9baea174787b47cfdcca7917605",
            "b05f2f54dc864de4be3074c4f9ad7d36",
            "f77b0189f69a46e8bead1f0d5147f08e",
            "1df4493809ee46a39606e261e0307d86",
            "eddfa8b95bef4f2a90eabbbf5beb44f3",
            "732f0b70b0ef49499d6561a7bb6ad501",
            "45d1b5f21e934f23b9554187e87ea044",
            "8dbee6ae34fa42c6bf4aac2b23db1b85",
            "ebe80713abc940c5b809f797efc4a5a2",
            "a36c3b821f704f129925652a6b3fd900",
            "e8528113119e4b97834bfc4773b727a1",
            "3b70fd8ff0cc4555863715125a082c95",
            "3fd3b8972df24895812a9e97b7c8f934",
            "ca4c6eb0606e43d5bb3122fe53381e45",
            "b9191abe97b04938840b2e768a724b41",
            "6fc0bea417b14f2d9468427a0b08cc2a"
          ]
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4619 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30d4a769c5544445bc13b613ba4cdee4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1155 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "732f0b70b0ef49499d6561a7bb6ad501"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_dataset, tokenized_eval_dataset"
      ],
      "metadata": {
        "id": "yFSryaOrEKQm",
        "outputId": "f8ae1be0-e778-4956-b72c-be4219fa1aae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['source', 'body', 'subject', 'ann0', 'ann1', 'ann2', 'body_wcount', 'subj_wcount', 'cleaned_emails', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 4619\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['source', 'body', 'subject', 'ann0', 'ann1', 'ann2', 'body_wcount', 'subj_wcount', 'cleaned_emails', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 1155\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "8prqmLk74DC2",
        "outputId": "29f63ff1-f121-4a73-8a5b-e1f48a108264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1734' max='1734' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1734/1734 37:30, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.714500</td>\n",
              "      <td>0.152499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.185400</td>\n",
              "      <td>0.139422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.171000</td>\n",
              "      <td>0.137965</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1734, training_loss=1.7728679551385265, metrics={'train_runtime': 2252.6082, 'train_samples_per_second': 6.152, 'train_steps_per_second': 0.77, 'total_flos': 9488682632871936.0, 'train_loss': 1.7728679551385265, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_save_path = \"fine_tuned_flan_t5_LP\"\n",
        "model.save_pretrained(model_save_path)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer.save_pretrained(model_save_path)"
      ],
      "metadata": {
        "id": "FgN3Xw66_dmV",
        "outputId": "e5337147-4499-4c09-ccf5-2eae0cb89afe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('fine_tuned_flan_t5_LP/tokenizer_config.json',\n",
              " 'fine_tuned_flan_t5_LP/special_tokens_map.json',\n",
              " 'fine_tuned_flan_t5_LP/spiece.model',\n",
              " 'fine_tuned_flan_t5_LP/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model and tokenizer\n",
        "Flan_T5_FT_LP_model = T5ForConditionalGeneration.from_pretrained(model_save_path)\n",
        "\n",
        "Flan_T5_model_FT_tokenizer = T5Tokenizer.from_pretrained(model_save_path)\n"
      ],
      "metadata": {
        "id": "Jg1XJBOZAbma",
        "outputId": "e4f0ecc1-ccff-40e9-c698-69f84bb2e26f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emails_for_score_df = Test_df.sample(n=20, random_state=32)\n",
        "emails_for_score_df"
      ],
      "metadata": {
        "id": "wtlJg_-YB2Fm",
        "outputId": "46f693cd-3e67-49c0-e7ff-c7b90997ba69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       source  \\\n",
              "7222         mann-k_sent_2424   \n",
              "4359    hernandez-j_inbox_299   \n",
              "5767      kaminski-v_sent_941   \n",
              "6817         lokey-t_inbox_85   \n",
              "1411       campbell-l_sent_73   \n",
              "3608       germany-c_sent_452   \n",
              "11633  shackleton-s_sent_6283   \n",
              "13868     whalley-g_inbox_414   \n",
              "327          beck-s_inbox_497   \n",
              "2492      delainey-d_sent_206   \n",
              "7706          may-l_inbox_478   \n",
              "8168         neal-s_inbox_118   \n",
              "518           beck-s_sent_399   \n",
              "7558       martin-t_inbox_108   \n",
              "3026        fischer-m_sent_14   \n",
              "12479      stclair-c_sent_253   \n",
              "3285     geaccone-t_inbox_444   \n",
              "7535          mann-k_sent_812   \n",
              "14071       whitt-m_inbox_438   \n",
              "3050         forney-j_inbox_7   \n",
              "\n",
              "                                                    body  \\\n",
              "7222   Hi Chris,  Happy New Year.\\nHope all is going ...   \n",
              "4359   To Our Valued  Traffic Report Clients,   Today...   \n",
              "5767   Molly,  This is an update on Anshuman.\\nPlease...   \n",
              "6817   Just A Reminder  Jennifer Lev's Baby Shower  W...   \n",
              "1411   Particpated in a Consolidated audit of two fac...   \n",
              "3608   We have a new Transco 6-6 contract.\\nTerm  9/6...   \n",
              "11633  Marie:  Shemeika Landry (X52552) and Shelli Sm...   \n",
              "13868  Headline:  \"Unocal, Tesoro, Pioneer, Equiva, R...   \n",
              "327    Sally,  As per our phone conversation, here is...   \n",
              "2492   Guys, I would like your opinion on this potent...   \n",
              "7706   With ECS (Enron Center South) rapidly approach...   \n",
              "8168   Scott   As discussed.\\nDate\\tWedsnesday 23rd M...   \n",
              "518    It is too late in the day in London for me to ...   \n",
              "7558   Tom,   I received an e-mail from Linda Carter ...   \n",
              "3026   Joe,  Attached is the Curtail200206.db file.\\n...   \n",
              "12479  Fred: I'm going to instruct RMS to send the $4...   \n",
              "3285   UH Team:  I have just been notified that the U...   \n",
              "7535   I need to set up a conference call with the ou...   \n",
              "14071  Dave,   I mentioned this project to Barry and ...   \n",
              "3050   Attention: The database will be undergoing mai...   \n",
              "\n",
              "                                                 subject  ann0  ann1  ann2  \\\n",
              "7222                                    Asset management   NaN   NaN   NaN   \n",
              "4359   Traffic Report outage and new product enhancem...   NaN   NaN   NaN   \n",
              "5767            Transition to Research Group - An Update   NaN   NaN   NaN   \n",
              "6817                 Reminder-Jennifer Lev's Baby Shower   NaN   NaN   NaN   \n",
              "1411                                       Weekly Report   NaN   NaN   NaN   \n",
              "3608                                   New Trco capacity   NaN   NaN   NaN   \n",
              "11633            procedure for opening brokerage account   NaN   NaN   NaN   \n",
              "13868  Unocal, Tesoro, Pioneer, Equiva, Reliant to Pr...   NaN   NaN   NaN   \n",
              "327       Sizing the Back-Office Outsourcing Opportunity   NaN   NaN   NaN   \n",
              "2492                                   GE Plastics Facts   NaN   NaN   NaN   \n",
              "7706        Broadcast Message - Trading Floor Stentofons   NaN   NaN   NaN   \n",
              "8168                                         Eddie Reitz   NaN   NaN   NaN   \n",
              "518                                     London Resources   NaN   NaN   NaN   \n",
              "7558                                        NWAL Meeting   NaN   NaN   NaN   \n",
              "3026                           Curtail200206.db Question   NaN   NaN   NaN   \n",
              "12479                                                RMS   NaN   NaN   NaN   \n",
              "3285                 UPDATE - UH Recruiting Date Change!   NaN   NaN   NaN   \n",
              "7535                                Edgecombe land lease   NaN   NaN   NaN   \n",
              "14071                                       Mist Storage   NaN   NaN   NaN   \n",
              "3050                                                 MOS   NaN   NaN   NaN   \n",
              "\n",
              "       body_wcount  subj_wcount  \\\n",
              "7222            70            2   \n",
              "4359           478            7   \n",
              "5767            94            7   \n",
              "6817            64            4   \n",
              "1411           110            2   \n",
              "3608            34            3   \n",
              "11633           31            5   \n",
              "13868          718           11   \n",
              "327             44            5   \n",
              "2492           150            3   \n",
              "7706           162            6   \n",
              "8168            50            2   \n",
              "518             70            2   \n",
              "7558            82            2   \n",
              "3026            96            2   \n",
              "12479           32            1   \n",
              "3285            61            6   \n",
              "7535            34            3   \n",
              "14071          156            2   \n",
              "3050            28            1   \n",
              "\n",
              "                                          cleaned_emails  \n",
              "7222   hi chris happy new year. hope all is going wel...  \n",
              "4359   to our valued traffic report clients today fri...  \n",
              "5767   molly this is an update on anshuman. please se...  \n",
              "6817   just a reminder jennifer levs baby shower wedn...  \n",
              "1411   particpated in a consolidated audit of two fac...  \n",
              "3608   we have a new transco 66 contract. term 96 930...  \n",
              "11633  marie shemeika landry x52552 and shelli smith ...  \n",
              "13868  headline unocal tesoro pioneer equiva reliant ...  \n",
              "327    sally as per our phone conversation here is a ...  \n",
              "2492   guys i would like your opinion on this potenti...  \n",
              "7706   with ecs enron center south rapidly approachin...  \n",
              "8168   scott as discussed. date wedsnesday 23rd may t...  \n",
              "518    it is too late in the day in london for me to ...  \n",
              "7558   tom i received an email from linda carter aski...  \n",
              "3026   joe attached is the curtail200206.db file. i h...  \n",
              "12479  fred im going to instruct rms to send the 4000...  \n",
              "3285   uh team i have just been notified that the uh ...  \n",
              "7535   i need to set up a conference call with the ou...  \n",
              "14071  dave i mentioned this project to barry and he ...  \n",
              "3050   attention the database will be undergoing main...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbde8459-e551-41ad-96ee-a8c70acf444f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>body</th>\n",
              "      <th>subject</th>\n",
              "      <th>ann0</th>\n",
              "      <th>ann1</th>\n",
              "      <th>ann2</th>\n",
              "      <th>body_wcount</th>\n",
              "      <th>subj_wcount</th>\n",
              "      <th>cleaned_emails</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>mann-k_sent_2424</td>\n",
              "      <td>Hi Chris,  Happy New Year.\\nHope all is going ...</td>\n",
              "      <td>Asset management</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>hi chris happy new year. hope all is going wel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4359</th>\n",
              "      <td>hernandez-j_inbox_299</td>\n",
              "      <td>To Our Valued  Traffic Report Clients,   Today...</td>\n",
              "      <td>Traffic Report outage and new product enhancem...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>478</td>\n",
              "      <td>7</td>\n",
              "      <td>to our valued traffic report clients today fri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5767</th>\n",
              "      <td>kaminski-v_sent_941</td>\n",
              "      <td>Molly,  This is an update on Anshuman.\\nPlease...</td>\n",
              "      <td>Transition to Research Group - An Update</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94</td>\n",
              "      <td>7</td>\n",
              "      <td>molly this is an update on anshuman. please se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6817</th>\n",
              "      <td>lokey-t_inbox_85</td>\n",
              "      <td>Just A Reminder  Jennifer Lev's Baby Shower  W...</td>\n",
              "      <td>Reminder-Jennifer Lev's Baby Shower</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>just a reminder jennifer levs baby shower wedn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1411</th>\n",
              "      <td>campbell-l_sent_73</td>\n",
              "      <td>Particpated in a Consolidated audit of two fac...</td>\n",
              "      <td>Weekly Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>110</td>\n",
              "      <td>2</td>\n",
              "      <td>particpated in a consolidated audit of two fac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3608</th>\n",
              "      <td>germany-c_sent_452</td>\n",
              "      <td>We have a new Transco 6-6 contract.\\nTerm  9/6...</td>\n",
              "      <td>New Trco capacity</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>we have a new transco 66 contract. term 96 930...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11633</th>\n",
              "      <td>shackleton-s_sent_6283</td>\n",
              "      <td>Marie:  Shemeika Landry (X52552) and Shelli Sm...</td>\n",
              "      <td>procedure for opening brokerage account</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31</td>\n",
              "      <td>5</td>\n",
              "      <td>marie shemeika landry x52552 and shelli smith ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13868</th>\n",
              "      <td>whalley-g_inbox_414</td>\n",
              "      <td>Headline:  \"Unocal, Tesoro, Pioneer, Equiva, R...</td>\n",
              "      <td>Unocal, Tesoro, Pioneer, Equiva, Reliant to Pr...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>718</td>\n",
              "      <td>11</td>\n",
              "      <td>headline unocal tesoro pioneer equiva reliant ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>beck-s_inbox_497</td>\n",
              "      <td>Sally,  As per our phone conversation, here is...</td>\n",
              "      <td>Sizing the Back-Office Outsourcing Opportunity</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44</td>\n",
              "      <td>5</td>\n",
              "      <td>sally as per our phone conversation here is a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2492</th>\n",
              "      <td>delainey-d_sent_206</td>\n",
              "      <td>Guys, I would like your opinion on this potent...</td>\n",
              "      <td>GE Plastics Facts</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>guys i would like your opinion on this potenti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7706</th>\n",
              "      <td>may-l_inbox_478</td>\n",
              "      <td>With ECS (Enron Center South) rapidly approach...</td>\n",
              "      <td>Broadcast Message - Trading Floor Stentofons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>162</td>\n",
              "      <td>6</td>\n",
              "      <td>with ecs enron center south rapidly approachin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8168</th>\n",
              "      <td>neal-s_inbox_118</td>\n",
              "      <td>Scott   As discussed.\\nDate\\tWedsnesday 23rd M...</td>\n",
              "      <td>Eddie Reitz</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>scott as discussed. date wedsnesday 23rd may t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>beck-s_sent_399</td>\n",
              "      <td>It is too late in the day in London for me to ...</td>\n",
              "      <td>London Resources</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "      <td>it is too late in the day in london for me to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7558</th>\n",
              "      <td>martin-t_inbox_108</td>\n",
              "      <td>Tom,   I received an e-mail from Linda Carter ...</td>\n",
              "      <td>NWAL Meeting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "      <td>tom i received an email from linda carter aski...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3026</th>\n",
              "      <td>fischer-m_sent_14</td>\n",
              "      <td>Joe,  Attached is the Curtail200206.db file.\\n...</td>\n",
              "      <td>Curtail200206.db Question</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96</td>\n",
              "      <td>2</td>\n",
              "      <td>joe attached is the curtail200206.db file. i h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12479</th>\n",
              "      <td>stclair-c_sent_253</td>\n",
              "      <td>Fred: I'm going to instruct RMS to send the $4...</td>\n",
              "      <td>RMS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>fred im going to instruct rms to send the 4000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3285</th>\n",
              "      <td>geaccone-t_inbox_444</td>\n",
              "      <td>UH Team:  I have just been notified that the U...</td>\n",
              "      <td>UPDATE - UH Recruiting Date Change!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61</td>\n",
              "      <td>6</td>\n",
              "      <td>uh team i have just been notified that the uh ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7535</th>\n",
              "      <td>mann-k_sent_812</td>\n",
              "      <td>I need to set up a conference call with the ou...</td>\n",
              "      <td>Edgecombe land lease</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34</td>\n",
              "      <td>3</td>\n",
              "      <td>i need to set up a conference call with the ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14071</th>\n",
              "      <td>whitt-m_inbox_438</td>\n",
              "      <td>Dave,   I mentioned this project to Barry and ...</td>\n",
              "      <td>Mist Storage</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>156</td>\n",
              "      <td>2</td>\n",
              "      <td>dave i mentioned this project to barry and he ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3050</th>\n",
              "      <td>forney-j_inbox_7</td>\n",
              "      <td>Attention: The database will be undergoing mai...</td>\n",
              "      <td>MOS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>attention the database will be undergoing main...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbde8459-e551-41ad-96ee-a8c70acf444f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fbde8459-e551-41ad-96ee-a8c70acf444f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fbde8459-e551-41ad-96ee-a8c70acf444f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8e0a1e96-c8f5-42cd-8dc0-16ee63deb7cd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e0a1e96-c8f5-42cd-8dc0-16ee63deb7cd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8e0a1e96-c8f5-42cd-8dc0-16ee63deb7cd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_919a15e2-c329-4146-a8f6-e84d3e6b56d4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('emails_for_score_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_919a15e2-c329-4146-a8f6-e84d3e6b56d4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('emails_for_score_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "emails_for_score_df",
              "summary": "{\n  \"name\": \"emails_for_score_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"mann-k_sent_2424\",\n          \"mann-k_sent_812\",\n          \"stclair-c_sent_253\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Hi Chris,  Happy New Year.\\nHope all is going well with you.\\nWe miss you!\\nI heard a rumor that the UI deal had an asset management aspect to it.\\nThe  guys around here are kicking around some different asset management ideas, so  I'm trying to get my hands on any docs which might give some insight into  some  different approaches.\\nDo you have anything you can email me?\\nThanks,\",\n          \"I need to set up a conference call with the outside lawyer who will be  drafting the lease (and other docs).\\nWho would like to participate in the  call?\\nHow about Thursday am?\\nThanks,\",\n          \"Fred: I'm going to instruct RMS to send the $40,000 to NationsBank of Texas, N.A.,  Account No.\\n3750494727, ABA Routing No.\\n111000012.\\nThis is what is in our  Master with them.\\nCarol\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Asset management\",\n          \"Edgecombe land lease\",\n          \"RMS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body_wcount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 170,\n        \"min\": 28,\n        \"max\": 718,\n        \"num_unique_values\": 18,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subj_wcount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 11,\n        \"num_unique_values\": 8,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_emails\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_subjects = []\n",
        "flan_T5_subjects = []\n",
        "finetuned_flan_T5_subjects = []\n",
        "\n",
        "\n",
        "for index, row in emails_for_score_df.iterrows():\n",
        "    email = row['body']\n",
        "    original_subject = row['subject']\n",
        "    prompt = f\"\"\"\n",
        "    Generate the subject line for the following email.\n",
        "\n",
        "    Email:\n",
        "    {email}\n",
        "\n",
        "    Subject:\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the device (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move both models to the same device\n",
        "    model.to(device)\n",
        "    Flan_T5_FT_LP_model.to(device)\n",
        "\n",
        "    original_model_input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    finetuned_model_input_ids = Flan_T5_model_FT_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "\n",
        "    original_model_outputs = model.generate(input_ids=original_model_input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    flan_T5_subjects.append(original_model_text_output)\n",
        "\n",
        "    instruct_model_outputs = Flan_T5_FT_LP_model.generate(input_ids=finetuned_model_input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = Flan_T5_model_FT_tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "    finetuned_flan_T5_subjects.append(instruct_model_text_output)\n",
        "\n",
        "    original_subjects.append(original_subject)\n",
        "\n",
        "zipped_subjects = list(zip(original_subjects, flan_T5_subjects, finetuned_flan_T5_subjects))\n",
        "\n",
        "Flan_T5_LP_df = pd.DataFrame(zipped_subjects, columns = ['original_subjects', 'T5_subjects', 'finetuned_flan_T5_subjects'])\n",
        "Flan_T5_LP_df"
      ],
      "metadata": {
        "id": "m45B3VOkBAvU",
        "outputId": "ef28978b-71e9-4295-d297-7ec6ff798b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    original_subjects  \\\n",
              "0                                    Asset management   \n",
              "1   Traffic Report outage and new product enhancem...   \n",
              "2            Transition to Research Group - An Update   \n",
              "3                 Reminder-Jennifer Lev's Baby Shower   \n",
              "4                                       Weekly Report   \n",
              "5                                   New Trco capacity   \n",
              "6             procedure for opening brokerage account   \n",
              "7   Unocal, Tesoro, Pioneer, Equiva, Reliant to Pr...   \n",
              "8      Sizing the Back-Office Outsourcing Opportunity   \n",
              "9                                   GE Plastics Facts   \n",
              "10       Broadcast Message - Trading Floor Stentofons   \n",
              "11                                        Eddie Reitz   \n",
              "12                                   London Resources   \n",
              "13                                       NWAL Meeting   \n",
              "14                          Curtail200206.db Question   \n",
              "15                                                RMS   \n",
              "16                UPDATE - UH Recruiting Date Change!   \n",
              "17                               Edgecombe land lease   \n",
              "18                                       Mist Storage   \n",
              "19                                                MOS   \n",
              "\n",
              "                                       T5_subjects  \\\n",
              "0                                 Asset Management   \n",
              "1                         FriedWire Traffic Report   \n",
              "2                                         Anshuman   \n",
              "3                       Jennifer Lev's Baby Shower   \n",
              "4                   Northern Border Pipeline Audit   \n",
              "5                             Transco 6-6 Contract   \n",
              "6                     Brokerage Account Procedures   \n",
              "7   Interactive Energy 2001 - Opening-Day Insights   \n",
              "8                           Sizing the Opportunity   \n",
              "9                                 GE/GE/GE/GE deal   \n",
              "10                        Stentofon Dialing Change   \n",
              "11                                  eddie's number   \n",
              "12                                          London   \n",
              "13                                   Certification   \n",
              "14                                Curtail200206.db   \n",
              "15                            NationsBank of Texas   \n",
              "16                         UH On Campus Recruiting   \n",
              "17                                 Conference Call   \n",
              "18                                      Mist Field   \n",
              "19                               MOS - Maintenance   \n",
              "\n",
              "                        finetuned_flan_T5_subjects  \n",
              "0                                 Asset Management  \n",
              "1                         FriedWire Traffic Report  \n",
              "2                                         Anshuman  \n",
              "3                       Jennifer Lev's Baby Shower  \n",
              "4                   Northern Border Pipeline Audit  \n",
              "5                             Transco 6-6 Contract  \n",
              "6                     Brokerage Account Procedures  \n",
              "7   Interactive Energy 2001 - Opening-Day Insights  \n",
              "8                           Sizing the Opportunity  \n",
              "9                                 GE/GE/GE/GE deal  \n",
              "10                        Stentofon Dialing Change  \n",
              "11                                  eddie's number  \n",
              "12                                          London  \n",
              "13                                   Certification  \n",
              "14                                Curtail200206.db  \n",
              "15                            NationsBank of Texas  \n",
              "16                         UH On Campus Recruiting  \n",
              "17                                 Conference Call  \n",
              "18                                      Mist Field  \n",
              "19                               MOS - Maintenance  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9f57e68-e8aa-49be-906e-3506e7da426d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_subjects</th>\n",
              "      <th>T5_subjects</th>\n",
              "      <th>finetuned_flan_T5_subjects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Asset management</td>\n",
              "      <td>Asset Management</td>\n",
              "      <td>Asset Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Traffic Report outage and new product enhancem...</td>\n",
              "      <td>FriedWire Traffic Report</td>\n",
              "      <td>FriedWire Traffic Report</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Transition to Research Group - An Update</td>\n",
              "      <td>Anshuman</td>\n",
              "      <td>Anshuman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Reminder-Jennifer Lev's Baby Shower</td>\n",
              "      <td>Jennifer Lev's Baby Shower</td>\n",
              "      <td>Jennifer Lev's Baby Shower</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Weekly Report</td>\n",
              "      <td>Northern Border Pipeline Audit</td>\n",
              "      <td>Northern Border Pipeline Audit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>New Trco capacity</td>\n",
              "      <td>Transco 6-6 Contract</td>\n",
              "      <td>Transco 6-6 Contract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>procedure for opening brokerage account</td>\n",
              "      <td>Brokerage Account Procedures</td>\n",
              "      <td>Brokerage Account Procedures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Unocal, Tesoro, Pioneer, Equiva, Reliant to Pr...</td>\n",
              "      <td>Interactive Energy 2001 - Opening-Day Insights</td>\n",
              "      <td>Interactive Energy 2001 - Opening-Day Insights</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sizing the Back-Office Outsourcing Opportunity</td>\n",
              "      <td>Sizing the Opportunity</td>\n",
              "      <td>Sizing the Opportunity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GE Plastics Facts</td>\n",
              "      <td>GE/GE/GE/GE deal</td>\n",
              "      <td>GE/GE/GE/GE deal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Broadcast Message - Trading Floor Stentofons</td>\n",
              "      <td>Stentofon Dialing Change</td>\n",
              "      <td>Stentofon Dialing Change</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Eddie Reitz</td>\n",
              "      <td>eddie's number</td>\n",
              "      <td>eddie's number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>London Resources</td>\n",
              "      <td>London</td>\n",
              "      <td>London</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NWAL Meeting</td>\n",
              "      <td>Certification</td>\n",
              "      <td>Certification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Curtail200206.db Question</td>\n",
              "      <td>Curtail200206.db</td>\n",
              "      <td>Curtail200206.db</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RMS</td>\n",
              "      <td>NationsBank of Texas</td>\n",
              "      <td>NationsBank of Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>UPDATE - UH Recruiting Date Change!</td>\n",
              "      <td>UH On Campus Recruiting</td>\n",
              "      <td>UH On Campus Recruiting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Edgecombe land lease</td>\n",
              "      <td>Conference Call</td>\n",
              "      <td>Conference Call</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Mist Storage</td>\n",
              "      <td>Mist Field</td>\n",
              "      <td>Mist Field</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>MOS</td>\n",
              "      <td>MOS - Maintenance</td>\n",
              "      <td>MOS - Maintenance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9f57e68-e8aa-49be-906e-3506e7da426d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9f57e68-e8aa-49be-906e-3506e7da426d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9f57e68-e8aa-49be-906e-3506e7da426d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb135528-bdbd-4544-adb6-a0c0acc87e9f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb135528-bdbd-4544-adb6-a0c0acc87e9f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb135528-bdbd-4544-adb6-a0c0acc87e9f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bf373c1f-4b31-4944-8745-8a2185ab49ff\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Flan_T5_LP_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bf373c1f-4b31-4944-8745-8a2185ab49ff button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Flan_T5_LP_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Flan_T5_LP_df",
              "summary": "{\n  \"name\": \"Flan_T5_LP_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"original_subjects\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Asset management\",\n          \"Edgecombe land lease\",\n          \"RMS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T5_subjects\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Asset Management\",\n          \"Conference Call\",\n          \"NationsBank of Texas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"finetuned_flan_T5_subjects\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Asset Management\",\n          \"Conference Call\",\n          \"NationsBank of Texas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=flan_T5_subjects,\n",
        "    references=original_subjects,\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "finetuned_model_results = rouge.compute(\n",
        "    predictions=finetuned_flan_T5_subjects,\n",
        "    references=original_subjects,\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('FLAN T5 Base Model:')\n",
        "print(original_model_results)\n",
        "print('\\nFINETUNED FLAN T5 BASE MODEL:')\n",
        "print(finetuned_model_results)"
      ],
      "metadata": {
        "id": "Lufz_SVBDS5B",
        "outputId": "117c567a-2b4b-4440-ab13-c2f70662e37e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLAN T5 Base Model:\n",
            "{'rouge1': 0.4021085858585859, 'rouge2': 0.17678571428571427, 'rougeL': 0.39109848484848486, 'rougeLsum': 0.3942424242424243}\n",
            "\n",
            "FINETUNED FLAN T5 BASE MODEL:\n",
            "{'rouge1': 0.4021085858585859, 'rouge2': 0.17678571428571427, 'rougeL': 0.39109848484848486, 'rougeLsum': 0.3942424242424243}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**flan_t5_base_original_model**"
      ],
      "metadata": {
        "id": "OnDeQ_KnAWai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flan_t5_base_original_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base', torch_dtype=torch.bfloat16)\n",
        "flan_t5_base_tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "print(\"For Model : FLAN-T5-Base \\n\",print_number_of_trainable_model_parameters(flan_t5_base_original_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ufBICyAosbw",
        "outputId": "07916456-b5c3-4685-8e9e-235827bc79c0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Model : FLAN-T5-Base \n",
            " Trainable model parameters: 247577856\n",
            "All model parameters: 247577856\n",
            "Percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flan_t5_base_tokenizer.special_tokens_map"
      ],
      "metadata": {
        "id": "2-a_H6f06elE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Flan T5 Small Model**"
      ],
      "metadata": {
        "id": "JU6tvjt2pbJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flan_t5_small_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.bfloat16)\n",
        "# flan_t5_small_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "print(\"For Model : Flan-t5-small \\n\",print_number_of_trainable_model_parameters(flan_t5_small_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186,
          "referenced_widgets": [
            "efd9774844034197a1642d921de0f1a8",
            "bbb7558ef2ce42eabad4554577810d64",
            "60bafab258324300bb39c46cd9f37f98",
            "b2de8e70619d46c0800a489ec118ff60",
            "727fa3ec29b24f0689c79aba203f6ca2",
            "12125b0a2d114f7f9bbca8b9684dd61c",
            "7db63ff48a8543b7aa0a16fadd2a2f34",
            "30da70ee1acf48e08b12d65df2bc5614",
            "abb5ee6bb64246b8b71bc120dbaa5794",
            "d9cdf21d4ceb4900a62e49389da304b3",
            "796fb397a4ea40b880e2d667ecbe4843",
            "02fa1934432648c8b5f9537e6fa2a49d",
            "9c3b8da68ab04423a5c0dc2f9642292f",
            "8e90df0c460348a6b19c463eeef26879",
            "40f6253703cf432cbfe5659ce422f7e1",
            "9e58512151d34d27be43a294b105ed87",
            "10ddf730a60a4d4bbe0da1b59aed7560",
            "289cb1838aa64612808451f6bdf25f81",
            "2bbd2eb1d40c4218b7997982c10e5a1d",
            "f2cb2bc5d32b444b80f6334fd879ca79",
            "c52aad7389b34312aa1d0497824893dd",
            "28f98c9b011c4da49ba3c7b42068bb8f",
            "f18d8b482eb84f4a97dc182ab679444e",
            "3961a5f4369446d881055b72c282b8f2",
            "9a465303403249d2b8627ba98d4a3499",
            "43aa877170bb44c8846e62a871c3de01",
            "f12f706f8a8645dc985a0e08faed2c02",
            "edaed9d68f4848e796218299bb5f8ceb",
            "98672a88021a4557b392607e085ba8fc",
            "ec1e174126b3476d8e7d672684b5357a",
            "596a91deb36d4b859d28d6ab1e0dc0c6",
            "6c9a09f9d6c24e78960ef681a9bb7479",
            "331ae92ef9924d84811a56003c1090f1"
          ]
        },
        "id": "SpTzBk9jEv_y",
        "outputId": "54ca83aa-7c84-4cfe-faf8-67717845d4c0"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efd9774844034197a1642d921de0f1a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02fa1934432648c8b5f9537e6fa2a49d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f18d8b482eb84f4a97dc182ab679444e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Model : Flan-t5-small \n",
            " Trainable model parameters: 76961152\n",
            "All model parameters: 76961152\n",
            "Percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flan-t5-base vs. flan-t5-small parameters\n",
        "247577856-76961152"
      ],
      "metadata": {
        "id": "iLGrsgJ2E35P",
        "outputId": "ba193095-31a4-4a3e-d172-8f348a25c3d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170616704"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test the Model with Zero Shot Inferencing**"
      ],
      "metadata": {
        "id": "ilaYbjowrNVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using a pre-trained model from Hugging Face/sources - FLAN-T5-Base .**"
      ],
      "metadata": {
        "id": "IV3wSp9HRSxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 9\n",
        "\n",
        "email = Train_dataset['cleaned_emails'][index]\n",
        "subject = Train_dataset['subject'][index]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Generate the subject line for the following email.\n",
        "\n",
        "Email:\n",
        "{email}\n",
        "\n",
        "Subject:\n",
        "\"\"\"\n",
        "\n",
        "inputs = flan_t5_base_tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "# Move input tensors to the same device as the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "inputs = {k: v.to(flan_t5_base_original_model.device) for k, v in inputs.items()}\n",
        "\n",
        "\n",
        "output = flan_t5_base_tokenizer.decode(\n",
        "    flan_t5_base_original_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=200,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE ORIGINAL HUMAN ANNOTED SUBJECT LINE :\\n{subject}\\n')\n",
        "print(dash_line)\n",
        "print(f'FLAN-T5 MODEL GENERATION - ZERO SHOT SUBJECT LINE:\\n{output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpNTTyqsvQS-",
        "outputId": "6dd90065-30c4-459e-daff-721aefd59538"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Generate the subject line for the following email.\n",
            "\n",
            "Email:\n",
            "edmund i have reviewed the long descriptions i was given for the credit derivatives i cant tell if they are current and have substantial comments i have attached what i have come up with sorry its in 2 pieces. basically i dont think we should be restating something in the long description that is already covered sometimes with different language in the gtc this only creates an ambiguity and is not necessary to form a complete contract. my other concern and i have not been able to draft language to fix it is that i cant find any definition of the seller payment amount and i dont think the buyer payment language works can you give me a call so we can discuss my concerns\n",
            "\n",
            "Subject:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE ORIGINAL HUMAN ANNOTED SUBJECT LINE :\n",
            "EOL Credit Derivatives - Long Descriptions\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "FLAN-T5 MODEL GENERATION - ZERO SHOT SUBJECT LINE:\n",
            "Credit Derivatives\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using a pre-trained model from Hugging Face etc- FLAN-T5-SMALL .**"
      ],
      "metadata": {
        "id": "slm6KkVEF_xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = flan_t5_base_tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "# Move input tensors to the same device as the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "\n",
        "output = flan_t5_base_tokenizer.decode(\n",
        "    flan_t5_small_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=200,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE ORIGINAL HUMAN ANNOTED SUBJECT LINE :\\n{subject}\\n')\n",
        "print(dash_line)\n",
        "print(f'FLAN-T5-SMALL MODEL GENERATION - ZERO SHOT SUBJECT LINE:\\n{output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYLYJUzZG_pd",
        "outputId": "dee6b023-48f2-444e-b6f8-156d4083e0fc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Generate the subject line for the following email.\n",
            "\n",
            "Email:\n",
            "edmund i have reviewed the long descriptions i was given for the credit derivatives i cant tell if they are current and have substantial comments i have attached what i have come up with sorry its in 2 pieces. basically i dont think we should be restating something in the long description that is already covered sometimes with different language in the gtc this only creates an ambiguity and is not necessary to form a complete contract. my other concern and i have not been able to draft language to fix it is that i cant find any definition of the seller payment amount and i dont think the buyer payment language works can you give me a call so we can discuss my concerns\n",
            "\n",
            "Subject:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE ORIGINAL HUMAN ANNOTED SUBJECT LINE :\n",
            "EOL Credit Derivatives - Long Descriptions\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "FLAN-T5-SMALL MODEL GENERATION - ZERO SHOT SUBJECT LINE:\n",
            "Credit Derivatives\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By testing with various models with the zero shot inferencing, we can see that the model struggles to extract the same subject line compared to the baseline subject, but it does pull out some important information from the email which indicates the models can be fine-tuned to the task at hand.**"
      ],
      "metadata": {
        "id": "C7S2UVFV8ZND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Performing Full Fine-Tuning using FLAN-T5 BASE MODEL**"
      ],
      "metadata": {
        "id": "3kTvPTm2wFVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "# # # Define special tokens\n",
        "# # special_tokens = {\n",
        "# #     \"additional_special_tokens\": [\"<EMAIL>\", \"</EMAIL>\"]\n",
        "# # }\n",
        "\n",
        "# # # Add special tokens to the tokenizer\n",
        "# # tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "\n",
        "# # Load the model\n",
        "# model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "# Resize the model's embeddings to accommodate the new tokens\n",
        "flan_t5_base_original_model.resize_token_embeddings(len(flan_t5_base_tokenizer))\n",
        "\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    start_prompt = 'Generate subject line for the email.\\n\\nEmail:'\n",
        "    end_prompt = '\\nSubject:\\n'\n",
        "    inputs = [start_prompt + email + end_prompt for email in examples['cleaned_emails']]\n",
        "    model_inputs = flan_t5_base_tokenizer(inputs, max_length=512, truncation=True, padding='max_length')\n",
        "\n",
        "    labels = flan_t5_base_tokenizer(examples['subject'], max_length=15, truncation=True, padding='max_length')\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = Train_dataset.map(tokenize_function, batched=True, remove_columns=Train_dataset.column_names)\n"
      ],
      "metadata": {
        "id": "bKNmBevDVfmG",
        "outputId": "a31f3e3a-cf3c-4692-cb78-3c1f4d519818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5eb20e66ffd041b0913ca612da305c1e",
            "b4c468e128c947fdbbc96e5696b0f1e4",
            "c9c1492eaf904461b0e554a01259b167",
            "1f6ceabfaf2f43e1a3890e1bc41f90bd",
            "dab896cb177a487c97b74d5798253b97",
            "cdaf84f879f64c34a61da5992336ac03",
            "97ab798a668f4f769408c82aefd3e5fb",
            "49a2db8634724944b675f6b1068684fb",
            "577d0cd38dec475ebdb45ad1e197b86f",
            "3230f592e16b4c279ee4e92dc9bd3490",
            "9d73a99b457d4252b5de5062d216d0e0"
          ]
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4619 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5eb20e66ffd041b0913ca612da305c1e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = Dataset.from_pandas(dataset_df)"
      ],
      "metadata": {
        "id": "Dhgp_1YuGFLe"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_full_dataset = full_dataset.map(tokenize_function, batched=True, remove_columns=full_dataset.column_names)"
      ],
      "metadata": {
        "id": "3_-CBdF6GavI",
        "outputId": "fed42dd7-fce2-4389-8fb5-c01181d9147a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8e47ed7f81ed4e1e82335b4b3bda2247",
            "f5809067f9e14175a08f8464be80d653",
            "5fe96090dae54689809dbe8b0ff0a0ca",
            "89e0141f4a884a0e8e03b4b2bbed1f27",
            "4054cd2fbe484e27a70648bd5baffd6d",
            "e544eec96f994bfebbdde3f41f720c31",
            "c8158ecaa9b340eeb855e48e7e552955",
            "a3abddc18f024dc39f65444c47c7f278",
            "e7906edcf5f642babea0d43876f400bb",
            "90a098b7e47c4213b80241b9dbcb11fd",
            "00995755b0d44067a89e0120321dbf3b"
          ]
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14436 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e47ed7f81ed4e1e82335b4b3bda2247"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_full_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4gF6D6Qq0Se",
        "outputId": "5016b042-66e9-462e-fe89-b3c0adbd84e0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 14436\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test\n",
        "split_dataset = tokenized_full_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = split_dataset['train']\n",
        "test_dataset = split_dataset['test']"
      ],
      "metadata": {
        "id": "DCfVV097WbZL"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "id": "2pDOF9rv8eRY",
        "outputId": "b0be77d7-b248-46ed-890e-3778eddaae23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 11548\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 2888\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    learning_rate=0.0001,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")"
      ],
      "metadata": {
        "id": "ckExw6k-Wq50"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=flan_t5_base_original_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=flan_t5_base_tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)\n",
        "\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Uo6VC5P6Wv1X",
        "outputId": "eaa341fc-8165-4708-b70a-05368ed25296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5775' max='8661' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5775/8661 1:11:19 < 35:39, 1.35 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.644100</td>\n",
              "      <td>1.244680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='722' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 24/722 00:05 < 02:35, 4.50 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8661' max='8661' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8661/8661 1:51:40, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.644100</td>\n",
              "      <td>1.244680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.912500</td>\n",
              "      <td>1.232297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.766400</td>\n",
              "      <td>1.231620</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8661, training_loss=2.3930341022254935, metrics={'train_runtime': 6701.21, 'train_samples_per_second': 5.17, 'train_steps_per_second': 1.292, 'total_flos': 2.372044512559104e+16, 'train_loss': 2.3930341022254935, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the fine-tuned model and tokenizer\n",
        "save_directory = \"./finetuned_flan_t5_base\"\n",
        "flan_t5_base_original_model.save_pretrained(save_directory)\n",
        "flan_t5_base_tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "# Zip the saved model files\n",
        "zip_filename = \"finetuned_flan_t5_base.zip\"\n",
        "shutil.make_archive(base_name=\"finetuned_flan_t5_base\", format=\"zip\", root_dir=save_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "S6gF7_J8uzEy",
        "outputId": "e30ab722-b7ef-4970-aa1a-10c3aefa28c5"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/finetuned_flan_t5_base.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the zipped checkpoint\n",
        "files.download(zip_filename)"
      ],
      "metadata": {
        "id": "qWhDAJVuCFmB",
        "outputId": "d9d42c21-4801-4071-be73-62b9473b767a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_854a9f32-f296-49f4-b6fe-d6e8ca1d000e\", \"finetuned_flan_t5_base.zip\", 393686780)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Unzip model checkpoint as it is zipped\n",
        "# # !unzip finetuned_flan_t5_base.zip -d ./finetuned_flan_t5_base\n",
        "\n",
        "# # Load the tokenizer\n",
        "# tokenizer = T5Tokenizer.from_pretrained('t5-base', legacy=False)\n",
        "\n",
        "# # Add special tokens to the tokenizer\n",
        "# num_added_tokens = tokenizer.add_special_tokens(special_tokens_map)\n",
        "\n",
        "\n",
        "# model_path = \"./finetuned_flan_t5_base\"\n",
        "# finetuned_tokenizer = T5Tokenizer.from_pretrained(model_path,  legacy=False)\n",
        "# finetuned_model = T5ForConditionalGeneration.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "XJd20rDqvIM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./finetuned_flan_t5_base\"\n",
        "finetuned_tokenizer = T5Tokenizer.from_pretrained(model_path,  legacy=False)\n",
        "finetuned_model = T5ForConditionalGeneration.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "j0l1kvYvGKIT",
        "outputId": "c78119d4-d42d-417e-a71e-dfca924c4b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"For Finetuned Model : Flan-t5 \\n\",print_number_of_trainable_model_parameters(finetuned_model))"
      ],
      "metadata": {
        "id": "qOAE40aKGtR-",
        "outputId": "ebf31f13-e47a-4945-8f04-884c85243529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Finetuned Model : Flan-t5 \n",
            " Trainable model parameters: 247534848\n",
            "All model parameters: 247534848\n",
            "Percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load special tokens from JSON file\n",
        "with open('/content/finetuned_flan_t5_base/special_tokens_map.json', 'r') as file:\n",
        "    special_tokens_map = json.load(file)\n",
        "\n",
        "# Print special tokens to verify\n",
        "print(special_tokens_map)"
      ],
      "metadata": {
        "id": "mjIfz8qkD7vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the Flan T5-Base Model Quantitatively (with ROUGE Metric)**\n",
        "The ROUGE metric helps quantify the validity of subject lines produced by models. It compares subjects to a \"Annoted baseline\" subject which is usually created by a human. While not perfect, it does indicate the overall increase in subject line generatiion effectiveness that we have accomplished by fine-tuning."
      ],
      "metadata": {
        "id": "os-472avsQlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Saved Finetuned Model and Tokenizer**"
      ],
      "metadata": {
        "id": "xxDoUanxvRov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emails_for_score_df = Train_df.sample(n=10, random_state=32)\n",
        "emails_for_score_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pMYOOca77uGV",
        "outputId": "03d0bb57-c144-4b24-9a74-f43091f9d91a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     source  \\\n",
              "12278     smith-m_inbox_340   \n",
              "6194         lay-k_inbox_15   \n",
              "3399    germany-c_sent_1052   \n",
              "7541        mann-k_sent_880   \n",
              "939         buy-r_inbox_497   \n",
              "401        beck-s_inbox_746   \n",
              "1224   campbell-l_inbox_474   \n",
              "10307    sanchez-m_inbox_62   \n",
              "8625      nemec-g_sent_2163   \n",
              "13145    taylor-m_inbox_299   \n",
              "\n",
              "                                                    body  \\\n",
              "12278  Here is the information that you guys had aske...   \n",
              "6194   Dr. Kenneth L. Lay Chairman of the Board Enron...   \n",
              "3399   This deal has been entered a CNG South Citygat...   \n",
              "7541   Matt, Since so much of this related to tax, I ...   \n",
              "939    As you may have become aware, the company rece...   \n",
              "401    Dear Nancy, Sally & Janet -  Did you have a wo...   \n",
              "1224   Market Participants:  Attached below are the v...   \n",
              "10307  20K and Relay Benefiting Assist the Officer Oc...   \n",
              "8625   Mark,  I talked with Jeff Stone this morning c...   \n",
              "13145  In order to complete our files, please send co...   \n",
              "\n",
              "                                                 subject  ann0  ann1  ann2  \\\n",
              "12278                                       Western Coal   NaN   NaN   NaN   \n",
              "6194   Three proposals, following up our recent meeting.   NaN   NaN   NaN   \n",
              "3399                  Deal 218918, McIntosh Partnerships   NaN   NaN   NaN   \n",
              "7541   Enron - Livingston County PRIVILEGED AND CONFI...   NaN   NaN   NaN   \n",
              "939                                Securities Litigation   NaN   NaN   NaN   \n",
              "401                                  December Newsletter   NaN   NaN   NaN   \n",
              "1224   Version Mapping for January 2001 and May 2001 ...   NaN   NaN   NaN   \n",
              "10307      LAST CALL:  RACE REGISTRATION - 20K and Relay   NaN   NaN   NaN   \n",
              "8625                          Station 13 Petition Status   NaN   NaN   NaN   \n",
              "13145                        Swapco -- Outstanding Items   NaN   NaN   NaN   \n",
              "\n",
              "       body_wcount  subj_wcount  \\\n",
              "12278           51            2   \n",
              "6194          1325            7   \n",
              "3399            48            4   \n",
              "7541            68            7   \n",
              "939            128            2   \n",
              "401            183            2   \n",
              "1224            65           10   \n",
              "10307          130            8   \n",
              "8625           143            4   \n",
              "13145          241            4   \n",
              "\n",
              "                                          cleaned_emails  \n",
              "12278  here is the information that you guys had aske...  \n",
              "6194   dr. kenneth l. lay chairman of the board enron...  \n",
              "3399   this deal has been entered a cng south citygat...  \n",
              "7541   matt since so much of this related to tax i th...  \n",
              "939    as you may have become aware the company recei...  \n",
              "401    dear nancy sally janet did you have a wonderfu...  \n",
              "1224   market participants attached below are the ver...  \n",
              "10307  20k and relay benefiting assist the officer oc...  \n",
              "8625   mark i talked with jeff stone this morning con...  \n",
              "13145  in order to complete our files please send cop...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f807eab0-892e-4133-9305-d644ef973080\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>body</th>\n",
              "      <th>subject</th>\n",
              "      <th>ann0</th>\n",
              "      <th>ann1</th>\n",
              "      <th>ann2</th>\n",
              "      <th>body_wcount</th>\n",
              "      <th>subj_wcount</th>\n",
              "      <th>cleaned_emails</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12278</th>\n",
              "      <td>smith-m_inbox_340</td>\n",
              "      <td>Here is the information that you guys had aske...</td>\n",
              "      <td>Western Coal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>here is the information that you guys had aske...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6194</th>\n",
              "      <td>lay-k_inbox_15</td>\n",
              "      <td>Dr. Kenneth L. Lay Chairman of the Board Enron...</td>\n",
              "      <td>Three proposals, following up our recent meeting.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1325</td>\n",
              "      <td>7</td>\n",
              "      <td>dr. kenneth l. lay chairman of the board enron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3399</th>\n",
              "      <td>germany-c_sent_1052</td>\n",
              "      <td>This deal has been entered a CNG South Citygat...</td>\n",
              "      <td>Deal 218918, McIntosh Partnerships</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48</td>\n",
              "      <td>4</td>\n",
              "      <td>this deal has been entered a cng south citygat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7541</th>\n",
              "      <td>mann-k_sent_880</td>\n",
              "      <td>Matt, Since so much of this related to tax, I ...</td>\n",
              "      <td>Enron - Livingston County PRIVILEGED AND CONFI...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>68</td>\n",
              "      <td>7</td>\n",
              "      <td>matt since so much of this related to tax i th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>buy-r_inbox_497</td>\n",
              "      <td>As you may have become aware, the company rece...</td>\n",
              "      <td>Securities Litigation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>2</td>\n",
              "      <td>as you may have become aware the company recei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>beck-s_inbox_746</td>\n",
              "      <td>Dear Nancy, Sally &amp; Janet -  Did you have a wo...</td>\n",
              "      <td>December Newsletter</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>183</td>\n",
              "      <td>2</td>\n",
              "      <td>dear nancy sally janet did you have a wonderfu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1224</th>\n",
              "      <td>campbell-l_inbox_474</td>\n",
              "      <td>Market Participants:  Attached below are the v...</td>\n",
              "      <td>Version Mapping for January 2001 and May 2001 ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65</td>\n",
              "      <td>10</td>\n",
              "      <td>market participants attached below are the ver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10307</th>\n",
              "      <td>sanchez-m_inbox_62</td>\n",
              "      <td>20K and Relay Benefiting Assist the Officer Oc...</td>\n",
              "      <td>LAST CALL:  RACE REGISTRATION - 20K and Relay</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>130</td>\n",
              "      <td>8</td>\n",
              "      <td>20k and relay benefiting assist the officer oc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8625</th>\n",
              "      <td>nemec-g_sent_2163</td>\n",
              "      <td>Mark,  I talked with Jeff Stone this morning c...</td>\n",
              "      <td>Station 13 Petition Status</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>143</td>\n",
              "      <td>4</td>\n",
              "      <td>mark i talked with jeff stone this morning con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13145</th>\n",
              "      <td>taylor-m_inbox_299</td>\n",
              "      <td>In order to complete our files, please send co...</td>\n",
              "      <td>Swapco -- Outstanding Items</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>241</td>\n",
              "      <td>4</td>\n",
              "      <td>in order to complete our files please send cop...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f807eab0-892e-4133-9305-d644ef973080')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f807eab0-892e-4133-9305-d644ef973080 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f807eab0-892e-4133-9305-d644ef973080');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2f4fcc2d-b6d3-4d69-af3f-4087c4134166\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f4fcc2d-b6d3-4d69-af3f-4087c4134166')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2f4fcc2d-b6d3-4d69-af3f-4087c4134166 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_35613d93-c5cc-4e79-b184-51d6cc21aee7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('emails_for_score_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_35613d93-c5cc-4e79-b184-51d6cc21aee7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('emails_for_score_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "emails_for_score_df",
              "summary": "{\n  \"name\": \"emails_for_score_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"nemec-g_sent_2163\",\n          \"lay-k_inbox_15\",\n          \"beck-s_inbox_746\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Mark,  I talked with Jeff Stone this morning concerning the petition.\\nThe  petition did not get filed on Friday as planned.\\nJeff had left for  Tallahassee prior to the FEDEX arriving on Friday morning.\\nThey also wanted  to have Katz-Kutter (our counsel in Fla.) sign the transmittal letter for the  petition prior to sending.\\nThis way the petition is sent by the customer and  not the utility.\\nBill Bryant at Katz-Kutter was unavailable Fri.  Jeff  assured me that they will get this filed today.\\nI asked him to call me once  filed.\\nWe need to start thinking about the best way to approach WFEC after this  petition is filed.\\nIt sounds like Alabama Electric Cooperative is the way to  approach this.\\nDo we know someone in our power trading group who works with  AEC?\\nMight be useful to approach it through that relationship.\",\n          \"Dr. Kenneth L. Lay Chairman of the Board Enron Corp.   \\tDear Dr. Lay,  We met less than a week ago, on Wednesday 16 May 2001, during the OECD Forum 2001 in Paris.\\nI'm an independent consultant and innovator, with a special interest in energy and new technologies.\\nI have more than ten years experience in research and innovation in economics, business and technology.\\nI attended the session on energy you chaired during that OECD Forum.\\nAfter the session, I had a discussion with you.\\nUnfortunately, your time was too short.\\nYou gave me your card and asked me to write you.\\nAs I told you, I think I can add value to your staff, bring new lines of businesses to Enron and with them, many new clients.\\nAnd above all, unprecedented profits.\\nI am writing you to propose my contribution in these purposes.\\nI'm mainly making three proposals to Enron.\\n1.- Working for Enron as an external consultant.\\nHere, I would rather like to work on assignments, medium or long term, with a preference for the following jobs: risk assessment and/or management, strategic analysis on geopolitical, macroeconomics and societal issues.\\nI think these are important tasks for a company like Enron.\\nThe current problems with Enron's Dabhol power plant in the Maharashtra state in India stresses the kind of importance I'm mentioning.\\nI can also conduct surveys and provide Enron with technical and fruitful information and policy recommendations.\\nI've done a job like that recently, on the oil-pipeline project in Chad and Cameroon.\\nAs you may already know, this is a $4 billion project recently launched, with the support of the World Bank, and led by three major energy firms: Exxon and Chevron of the USA, and Petronas of Malaysia.\\nI wrote a detailed and long report, which combined public and private sectors' concerns, and also communities' interests.\\nHaving operations worldwide, Enron I think needs the type of technical works I've done on that major energy project.\\nI have a good expertise in energy economics.\\nI attend international congresses on that subject, for instance in Boston in January 2000.\\nSince more than five years, as a journalist or as an independent consultant, I have been covering the works and studies of, or participated to workshops and seminar organized by, the IEA (International Energy Association).\\nI know Mr. Robert Priddle, IEA chair, who also attended that energy session during the OECD Forum 2001.\\nI know the work he and his team of experts have been doing.\\n2.- Being fully employed by Enron.\\nIn this respect, I would prefer to work as a researcher for either Enron Project Development and Management or Capital and Risk Management departments.\\nIn these fields, I've also innovated.\\nI've created among concepts, tools and processes.\\nFor instance, the \\\"Sensible Guide for Action\\\".\\nThis is a tool theoretically powerful and practically very efficacious.\\nIt's main goal is to help decision-makers, in both private and public sectors.\\nThe Sensible Guide for Action assists them in their approach to solve technical problems.\\nThe SGA is a five-leaf bough.\\nI've also created a method to assess a firm capacity to create wealth.\\nThis method can be adapted to fit some particular projects.\\nThe method is very useful in countries where there's no stocks market, and where capital markets are not sufficiently large.\\nThat's the case of underdeveloped countries in general, where yet the energy demand if forecast to grow the most in the coming decades.\\nEnron cannot overlook this, or miss the business and profit opportunities in this growth.\\n3.- The Business of Businesses.\\nDear Dr Lay, if you accept this third proposal, it will probably be the best investment Enron has ever made.\\nI'm an independent researcher and entrepreneur, with a strong quantitative analysis competence, and a multidisciplinary background, both by education and professionally.\\nI'm a graduate in mathematics and in mechanical engineering (University of Paris) and also in business and economics (Institut d'Etudes Politiques of Paris).\\nIn this third proposal I'm bringing to Enron two key inventions I've made, two types of financial products targeting consumers and companies.\\nI believe they will interest Enron.\\nThese products have a market potential worldwide, unlimited.\\nThey will create an entirely new industry: the business of businesses.\\nI'm currently looking for investors with whom I can launch those products.\\nWe will be the world leader here, and remain in that position for a long time before copycats try to reach us.\\nI've created the products, and nobody knows about them or about their extraordinary markets.\\nI started to talk to you about these products when we met, but you were hurrying, and the many solicitations and noises of the Forum made it difficult to explain my point.\\nI'm writing you as you asked me, because firstly I believe these products will interest Enron.\\nSecondly I know how these products will boost three types of Enron services: Online Marketplace; Broadband Services; and Energy & Commodities.\\nPlus, these products, and the business of businesses they create are an excellent placement for Enron.\\nAmong the many reasons why I believe my products will interest Enron are these:  (i) Their market is global.\\n(ii) They are directly related to consumption and savings.\\n(iii) They're excellent saving vehicles, for instance for pension or life insurance.\\n(iv) They concern payment transactions and transmissions (And thanks to information technology, costs here decrease while productivity will grow).\\n(v) They are both offline and online business (These products will be excellent for Enron e-business).\\n(vi) I want to be and remain a global leader.\\n(vii) The products' growth potential is borderless (viii) There's no competitor and before copycats arrive we would have strongly imposed ourselves as The Leader and the Reference, increasing chances that customers remain faithful to us.\\n(ix) My products will allow Enron to beat its competitors.\\n(x) Enron will earn a lot of revenues, many new clients, and very big and unprecedented profits.\\nI'm looking for investors willing to put around $7 million.\\nGiven that the revenues generated can very rapidly reach the range of $500 million to $1 billion, that initial $7 million is a wise and very profitable investment.\\nIf you're interested, I'm ready to present the products and its business scenario to you.\\nThe business model is very innovative, unprecedented.\\nThese products' market is the whole world.\\nBut the first three markets I would like to attack are the UK, Germany and moreover, Japan.\\nToday's news about Japan is rather bad.\\nEconomists and many observers see a declining Japan.\\nMe not.\\nThey may be right from a pure statistical and macroeconomic viewpoint.\\nBut they fail to see deeper.\\nThey overlook the other face of Japan.\\nFor my part, I see great business opportunities in Japan, today and for the coming decade.\\nParticularly for the financial products I'm proposing.\\nThese financial products I want Enron to launch with me in Japan, perfectly fit Japanese consumption manners, their problematic pension system, and life insurance structure there.\\nPublic pension systems are under pressure every where, particularly in Japan.\\nIn Germany they are trying to reform it.\\nBut there's no consensus in the governments (federal and states') or in the Parliaments (federal and states').\\nLast week, Chancellor Gerhard Schr?der won some parliamentary approval.\\nBut the package he proposed is far from solving the issue.\\nIn the meantime, problems may accumulate, the situation could worsen.\\nWhat seems sure is that in a foreseeable future, governments, not only in Germany but in all developed and ageing countries, will no longer be able to pay pensions at the level they have promised or are continuing to promise.\\nAn additional bad news, even company pensions will suffer.\\nIn today's \\\"Financial Times\\\" (Tuesday 22 May 2001, page 17), Peter Thompson, incoming chairman of the British National Association of Pension Funds \\\"warned UK workers that they would no longer rely on comfortable company\\\".\\nHe adds that \\\"many wold have to work until they were 75 -- 10 years longer than the\",\n          \"Dear Nancy, Sally & Janet -  Did you have a wonderful Thanksgiving?\\nOurs was very nice; Mark's sister, her husband and 2-year old daughter were here from California, and Mark's mom & her husband came in from D.C. (but they stayed in a hotel!).\\nLuckily, our aunt had the big dinner at her house - no trying to cook among the boxes!\\nHave you had an opportunity to review the December newsletter?\\nIf so, please let me know of any corrections or changes (Miranda gave me the corrected minutes).\\nMy plan is to drop it off to Sally Walker for copying first thing Monday morning.\\nIt will be crazy around here after noon Monday, and the computer will be off for a few days (Monday night 'til Wednesday night or Thursday) while we get set up in the new house .\\n.\\n.if the download didn't work and you need a copy to proof, just let me know and I'll swing by with one in the morning (our closing is not far from you, Nancy, so it won't be a problem).\\nThanks!\\nRobin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Station 13 Petition Status\",\n          \"Three proposals, following up our recent meeting.\",\n          \"December Newsletter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ann2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body_wcount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 386,\n        \"min\": 48,\n        \"max\": 1325,\n        \"num_unique_values\": 10,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subj_wcount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 10,\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_emails\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emails = emails_for_score_df['body']\n",
        "original_subjects = emails_for_score_df['subject']\n",
        "original_subjects\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6FaMiCNtOgs",
        "outputId": "5fd60c38-200b-4b68-eafc-51022abe25d7"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12278                                         Western Coal\n",
              "6194     Three proposals, following up our recent meeting.\n",
              "3399                    Deal 218918, McIntosh Partnerships\n",
              "7541     Enron - Livingston County PRIVILEGED AND CONFI...\n",
              "939                                  Securities Litigation\n",
              "401                                    December Newsletter\n",
              "1224     Version Mapping for January 2001 and May 2001 ...\n",
              "10307        LAST CALL:  RACE REGISTRATION - 20K and Relay\n",
              "8625                            Station 13 Petition Status\n",
              "13145                          Swapco -- Outstanding Items\n",
              "Name: subject, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn8SNYNUBLbF",
        "outputId": "31184eb6-3f84-4553-bae4-d97bf4b83ac9"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 2888\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_subjects = []\n",
        "flan_T5_subjects = []\n",
        "finetuned_flan_T5_subjects = []\n",
        "\n",
        "\n",
        "for index, row in emails_for_score_df.iterrows():\n",
        "    email = row['body']\n",
        "    original_subject = row['subject']\n",
        "    prompt = f\"\"\"\n",
        "    Generate the subject line for the following email.\n",
        "\n",
        "    Email:\n",
        "    {email}\n",
        "\n",
        "    Subject:\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the device (GPU if available, otherwise CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move both models to the same device\n",
        "    flan_t5_base_original_model.to(device)\n",
        "    finetuned_model.to(device)\n",
        "\n",
        "    original_model_input_ids = flan_t5_base_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "    finetuned_model_input_ids = finetuned_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "\n",
        "    original_model_outputs = flan_t5_base_original_model.generate(input_ids=original_model_input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = flan_t5_base_tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    flan_T5_subjects.append(original_model_text_output)\n",
        "\n",
        "    instruct_model_outputs = finetuned_model.generate(input_ids=finetuned_model_input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = finetuned_tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "    finetuned_flan_T5_subjects.append(instruct_model_text_output)\n",
        "\n",
        "    original_subjects.append(original_subject)\n",
        "\n",
        "zipped_subjects = list(zip(original_subjects, flan_T5_subjects, finetuned_flan_T5_subjects))\n",
        "\n",
        "Flan_T5_df = pd.DataFrame(zipped_subjects, columns = ['original_subjects', 'T5_subjects', 'finetuned_flan_T5_subjects'])\n",
        "Flan_T5_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "0SUG4spPuGPQ",
        "outputId": "f5ffc477-77c7-4e40-8a69-fed94af3ead8"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1838 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   original_subjects  \\\n",
              "0                                       Western Coal   \n",
              "1  Three proposals, following up our recent meeting.   \n",
              "2                 Deal 218918, McIntosh Partnerships   \n",
              "3  Enron - Livingston County PRIVILEGED AND CONFI...   \n",
              "4                              Securities Litigation   \n",
              "5                                December Newsletter   \n",
              "6  Version Mapping for January 2001 and May 2001 ...   \n",
              "7      LAST CALL:  RACE REGISTRATION - 20K and Relay   \n",
              "8                         Station 13 Petition Status   \n",
              "9                        Swapco -- Outstanding Items   \n",
              "\n",
              "                                 T5_subjects  \\\n",
              "0                                  WSCC coal   \n",
              "1                            OECD Forum 2001   \n",
              "2                         CNG South Citygate   \n",
              "3                           Tax Presentation   \n",
              "4                      Securities Litigation   \n",
              "5                        December Newsletter   \n",
              "6               January 2001 Version Mapping   \n",
              "7  20K and Relay - Benefiting Assist Officer   \n",
              "8                              WFEC Petition   \n",
              "9                    Signatures for ERMT LLC   \n",
              "\n",
              "                finetuned_flan_T5_subjects  \n",
              "0                                WSCC coal  \n",
              "1                          OECD Forum 2001  \n",
              "2                       CNG South Citygate  \n",
              "3                         Tax Presentation  \n",
              "4                    Securities Litigation  \n",
              "5                      December Newsletter  \n",
              "6             January 2001 Version Mapping  \n",
              "7  20K and Relay Benefiting Assist Officer  \n",
              "8                            WFEC Petition  \n",
              "9                  Signatures for ERMT LLC  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eac723eb-9ae8-411d-a845-9b112867910a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_subjects</th>\n",
              "      <th>T5_subjects</th>\n",
              "      <th>finetuned_flan_T5_subjects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Western Coal</td>\n",
              "      <td>WSCC coal</td>\n",
              "      <td>WSCC coal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Three proposals, following up our recent meeting.</td>\n",
              "      <td>OECD Forum 2001</td>\n",
              "      <td>OECD Forum 2001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Deal 218918, McIntosh Partnerships</td>\n",
              "      <td>CNG South Citygate</td>\n",
              "      <td>CNG South Citygate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Enron - Livingston County PRIVILEGED AND CONFI...</td>\n",
              "      <td>Tax Presentation</td>\n",
              "      <td>Tax Presentation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Securities Litigation</td>\n",
              "      <td>Securities Litigation</td>\n",
              "      <td>Securities Litigation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>December Newsletter</td>\n",
              "      <td>December Newsletter</td>\n",
              "      <td>December Newsletter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Version Mapping for January 2001 and May 2001 ...</td>\n",
              "      <td>January 2001 Version Mapping</td>\n",
              "      <td>January 2001 Version Mapping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LAST CALL:  RACE REGISTRATION - 20K and Relay</td>\n",
              "      <td>20K and Relay - Benefiting Assist Officer</td>\n",
              "      <td>20K and Relay Benefiting Assist Officer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Station 13 Petition Status</td>\n",
              "      <td>WFEC Petition</td>\n",
              "      <td>WFEC Petition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Swapco -- Outstanding Items</td>\n",
              "      <td>Signatures for ERMT LLC</td>\n",
              "      <td>Signatures for ERMT LLC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eac723eb-9ae8-411d-a845-9b112867910a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eac723eb-9ae8-411d-a845-9b112867910a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eac723eb-9ae8-411d-a845-9b112867910a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-00d1abdb-d4fd-4a97-b0fa-55133a7f2970\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00d1abdb-d4fd-4a97-b0fa-55133a7f2970')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-00d1abdb-d4fd-4a97-b0fa-55133a7f2970 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d7bcb76e-4d5f-480d-ba91-23d7c5555b15\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('Flan_T5_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d7bcb76e-4d5f-480d-ba91-23d7c5555b15 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('Flan_T5_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "Flan_T5_df",
              "summary": "{\n  \"name\": \"Flan_T5_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"original_subjects\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Station 13 Petition Status\",\n          \"Three proposals, following up our recent meeting.\",\n          \"December Newsletter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"T5_subjects\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"WFEC Petition\",\n          \"OECD Forum 2001\",\n          \"December Newsletter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"finetuned_flan_T5_subjects\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"WFEC Petition\",\n          \"OECD Forum 2001\",\n          \"December Newsletter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=flan_T5_subjects,\n",
        "    references=original_subjects,\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "finetuned_model_results = rouge.compute(\n",
        "    predictions=finetuned_flan_T5_subjects,\n",
        "    references=original_subjects,\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('FLAN T5 Base Model:')\n",
        "print(original_model_results)\n",
        "print('\\nFINETUNED FLAN T5 BASE MODEL:')\n",
        "print(finetuned_model_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnuLg7e_1_Kt",
        "outputId": "b23596d0-f975-4f9a-98dd-137aea4dad47"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLAN T5 Base Model:\n",
            "{'rouge1': 0.38186813186813184, 'rouge2': 0.26666666666666666, 'rougeL': 0.36190476190476184, 'rougeLsum': 0.35805860805860806}\n",
            "\n",
            "FINETUNED FLAN T5 BASE MODEL:\n",
            "{'rouge1': 0.38186813186813184, 'rouge2': 0.26666666666666666, 'rougeL': 0.36190476190476184, 'rougeLsum': 0.35805860805860806}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Finetuning results should show  improvement in all ROUGE metrics:**\n",
        "\n"
      ],
      "metadata": {
        "id": "-2t11zBHN8nM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Absolute percentage improvement of FINETUNED MODEL over HUMAN BASELINE\")\n",
        "\n",
        "improvement = (np.array(list(finetuned_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(finetuned_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ],
      "metadata": {
        "id": "cKtHUDqyNf4b",
        "outputId": "e90c2af0-d113-4aad-ea50-604a42314cec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of FINETUNED MODEL over HUMAN BASELINE\n",
            "rouge1: 0.00%\n",
            "rouge2: 0.00%\n",
            "rougeL: 0.00%\n",
            "rougeLsum: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Perform Parameter Efficient Fine-Tuning (PEFT)**\n",
        "Parameter Efficient Fine-Tuning (PEFT), which is more efficient than full fine-tuning and yields comparable results. PEFT, often referring to Low-Rank Adaptation (LoRA), enables fine-tuning with fewer compute resources, often a single GPU.\n",
        "\n",
        "LoRA produces a small adapter (a few MBs) while keeping the original LLM unchanged. During inference, this adapter is combined with the original LLM, allowing multiple adapters to reuse the same LLM and reducing memory requirements for various tasks."
      ],
      "metadata": {
        "id": "FoDFsTogOMTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup the PEFT/LoRA model for Fine-Tuning**"
      ],
      "metadata": {
        "id": "O0TgYeKuO-4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \\\n",
        "    loralib==0.1.1 \\\n",
        "    peft==0.3.0 --quiet"
      ],
      "metadata": {
        "id": "Od5iuL0YPKPU",
        "outputId": "66fd6195-b0ae-4785-8cb3-6c6af3439f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
        ")"
      ],
      "metadata": {
        "id": "eDAkW_4VO6qF"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(flan_t5_base_original_model, lora_config)\n",
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ],
      "metadata": {
        "id": "esd41UNmO6il",
        "outputId": "3cd6610f-fd1c-4f63-d828-97c7f918c8b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable model parameters: 3538944\n",
            "All model parameters: 251073792\n",
            "Percentage of trainable model parameters: 1.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset"
      ],
      "metadata": {
        "id": "uHDODVO9Q4Pt",
        "outputId": "3c4437ec-4873-4700-f2b4-dc6ffedf619f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 11548\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['input_ids', 'attention_mask', 'labels'],\n",
              "     num_rows: 2888\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset"
      ],
      "metadata": {
        "id": "QPI-afIzahgB",
        "outputId": "97a46868-7522-4afc-dc62-8fb9c6bd690b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 11548\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2888\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "# # Preprocess function\n",
        "# def preprocess_function(examples):\n",
        "#     inputs = tokenizer(examples['body'], max_length=512, truncation=True, padding=\"max_length\")\n",
        "#     targets = tokenizer(examples['lable'], max_length=128, truncation=True, padding=\"max_length\")\n",
        "#     return {'input_ids': inputs['input_ids'], 'attention_mask': inputs['attention_mask'], 'labels': targets['input_ids']} # Added attention_mask to the output\n",
        "\n",
        "# # Apply preprocessing\n",
        "# train_dataset = split_dataset['train'].map(preprocess_function, batched=True)\n",
        "# val_dataset = split_dataset['validation'].map(preprocess_function, batched=True)\n",
        "\n",
        "# Load base model\n",
        "model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "# Define LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "FIVCe35mZtlz",
        "outputId": "ba751da3-aa11-4856-adc6-604359330660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "UwNKgwWScPvy",
        "outputId": "f5d6179f-6436-4558-bfaf-af6aa54c5c68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul 26 14:56:47 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0              27W /  70W |   8251MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kill -9 <pid>"
      ],
      "metadata": {
        "id": "hbedsL4PcaRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = f'./peft-subjectline-training-{str(int(time.time()))}'\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=1,\n",
        "    max_steps=1,\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "xMBzuOTjiaiS",
        "outputId": "d2ee6de9-80d2-47de-815b-8a3ac041d791",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "id": "m-IZqqfui1FA",
        "outputId": "eaa2a62d-b909-4f1b-bbc4-46208cd98648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 2888\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peft_trainer.train()"
      ],
      "metadata": {
        "id": "gNK4EmpSinor",
        "outputId": "f823511f-bb13-48a5-8bb4-473bcbeb424d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/1 : < :, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "\n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'base_model.model.encoder.embed_tokens.weight', 'base_model.model.shared.weight', 'base_model.model.decoder.embed_tokens.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-8d72851eaa1f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpeft_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/memory.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No executable batch size found, reached zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_reduce_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2343\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2796\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2873\u001b[0m         \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_output_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m         \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2875\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_internal_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   3427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3429\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3431\u001b[0m         \u001b[0;31m# Push to the Hub when `save_model` is called by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   3492\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trainer.model is not a `PreTrainedModel`, only saving its state dict.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_safetensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3494\u001b[0;31m                     safetensors.torch.save_file(\n\u001b[0m\u001b[1;32m   3495\u001b[0m                         \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAFE_WEIGHTS_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3496\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36msave_file\u001b[0;34m(tensors, filename, metadata)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \"\"\"\n\u001b[0;32m--> 284\u001b[0;31m     \u001b[0mserialize_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\u001b[0m in \u001b[0;36m_flatten\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    481\u001b[0m             f\"\"\"\n\u001b[1;32m    482\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0mshare\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mlead\u001b[0m \u001b[0mto\u001b[0m \u001b[0mduplicate\u001b[0m \u001b[0mmemory\u001b[0m \u001b[0mon\u001b[0m \u001b[0mdisk\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mdifferences\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mloading\u001b[0m \u001b[0mthem\u001b[0m \u001b[0magain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mfailing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \n            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'base_model.model.encoder.embed_tokens.weight', 'base_model.model.shared.weight', 'base_model.model.decoder.embed_tokens.weight'}].\n            A potential way to correctly save your model is to use `save_model`.\n            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors\n            "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply LoRA to the model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=1,\n",
        "    gradient_accumulation_steps=8,  # Accumulate gradients over multiple steps\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=200,\n",
        "    fp16=True,  # Enable mixed precision training\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "PS2BCdU1YxUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained('path/to/save/finetuned_model')\n",
        "tokenizer.save_pretrained('path/to/save/finetuned_model')"
      ],
      "metadata": {
        "id": "rByaLl7oZZBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = f'./peft-subjectline-training-{str(int(time.time()))}'\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    auto_find_batch_size=True,\n",
        "    # learning_rate=1e-4, # Higher learning rate than full fine-tuning.\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    # logging_steps=10,\n",
        "    # max_steps=1\n",
        ")\n",
        "\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=split_dataset['test'],\n",
        ")\n",
        "\n",
        "\n",
        "peft_trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "Td3BbnnYPrhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model_path=\"./peft-subjectline-checkpoint-local\"\n",
        "\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ],
      "metadata": {
        "id": "mQIvcDX7YaEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
        "                                       './peft-dialogue-summary-checkpoint-from-s3/',\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       is_trainable=False)"
      ],
      "metadata": {
        "id": "swBbx2xffokn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wz0o7_vWSgON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the 'punkt' resource\n",
        "nltk.download('punkt')\n",
        "\n",
        "nltk.download('wordnet') # Download the WordNet corpus"
      ],
      "metadata": {
        "id": "vTP9c9DuNXhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "# Evaluate the generated subject lines\n",
        "def evaluate_metrics(true_subject, generated_subject):\n",
        "    # ROUGE-L\n",
        "    rougeL = scorer.score(true_subject, generated_subject)['rougeL'].fmeasure\n",
        "\n",
        "    # METEOR\n",
        "    meteor = meteor_score([word_tokenize(true_subject)], word_tokenize(generated_subject))\n",
        "\n",
        "    # SACREBLEU\n",
        "    sacre_bleu = sacrebleu.corpus_bleu([generated_subject], [[true_subject]]).score\n",
        "\n",
        "    return rougeL, meteor, sacre_bleu\n",
        "\n",
        "Flan_T5_df['rougeL'], Flan_T5_df['meteor'], Flan_T5_df['sacrebleu'] = zip(*Flan_T5_df.apply(\n",
        "    lambda row: evaluate_metrics(row['original_subjects'], row['T5_subjects']), axis=1))\n",
        "\n",
        "# Calculate average scores\n",
        "average_rougeL = Flan_T5_df['rougeL'].mean()\n",
        "average_meteor = Flan_T5_df['meteor'].mean()\n",
        "average_sacrebleu = Flan_T5_df['sacrebleu'].mean()\n",
        "\n",
        "print(f'Average ROUGE-L: {average_rougeL:.4f}')\n",
        "print(f'Average METEOR: {average_meteor:.4f}')\n",
        "print(f'Average SACREBLEU: {average_sacrebleu:.4f}')"
      ],
      "metadata": {
        "id": "xFBuePhiLDcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_dWxlbZQCTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#T5 Flan Base\n",
        "# Load the ROUGE metric\n",
        "rouge_metric = load_metric('rouge')\n",
        "\n",
        "def calculate_rouge_scores(predictions, references):\n",
        "    rouge_metric.add_batch(predictions=predictions, references=references)\n",
        "    result = rouge_metric.compute()\n",
        "    return {\n",
        "        'rouge1': result['rouge1'].mid.fmeasure * 100,\n",
        "        'rouge2': result['rouge2'].mid.fmeasure * 100,\n",
        "        'rougeL': result['rougeL'].mid.fmeasure * 100\n",
        "    }\n",
        "\n",
        "# Generate predictions and calculate ROUGE scores\n",
        "predictions = []\n",
        "references = []\n",
        "\n",
        "for example in test_dataset.shuffle(seed=42).select(range(20)):\n",
        "    input_ids = example['input_ids']\n",
        "    input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)  # Add batch dimension\n",
        "    outputs = finetuned_model.generate(input_ids)\n",
        "    pred = finetuned_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    ref = finetuned_tokenizer.decode(example['labels'], skip_special_tokens=True)\n",
        "\n",
        "    predictions.append(pred)\n",
        "    references.append(ref)\n",
        "\n",
        "# Calculate and print ROUGE scores for each test sample\n",
        "rouge_scores = []\n",
        "for pred, ref in zip(predictions, references):\n",
        "    score = calculate_rouge_scores([pred], [ref])\n",
        "    rouge_scores.append(score)\n",
        "    print(f\"Prediction: {pred}\\nReference: {ref}\\nROUGE Scores: {score}\\n\")\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "rouge_df = pd.DataFrame(rouge_scores)\n",
        "rouge_df"
      ],
      "metadata": {
        "id": "vQ-w7TxGZEV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)"
      ],
      "metadata": {
        "id": "rubayi3ZdWSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_test_df = test_df.sample(n=10, random_state=42)"
      ],
      "metadata": {
        "id": "SHpw9jHsefXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_test_df"
      ],
      "metadata": {
        "id": "258hkqQlevCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_subject_line(email_body):\n",
        "    inputs = finetuned_tokenizer(\"Generate a subject line for the following email.: \" + email_body, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    # Move inputs to the same device as the model\n",
        "    inputs = {k: v.to(finetuned_model.device) for k, v in inputs.items()}\n",
        "    # Access input_ids as a key in the dictionary\n",
        "    outputs = finetuned_model.generate(inputs['input_ids'], max_length=128, num_beams=4, early_stopping=True)\n",
        "    return finetuned_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Hw-_IgKYdlkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_test_df['generated_subject_line'] = small_test_df['cleaned_emails'].apply(generate_subject_line)\n",
        "small_test_df"
      ],
      "metadata": {
        "id": "HPLoCJgffW7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "\n",
        "# Evaluate the generated subject lines\n",
        "def evaluate_metrics(true_subject, generated_subject):\n",
        "    # Tokenize the input for METEOR\n",
        "    true_subject_tokens = nltk.word_tokenize(true_subject)\n",
        "    generated_subject_tokens = nltk.word_tokenize(generated_subject)\n",
        "\n",
        "    # ROUGE-L\n",
        "    rougeL = scorer.score(true_subject, generated_subject)['rougeL'].fmeasure\n",
        "\n",
        "    # METEOR\n",
        "    meteor = meteor_score([true_subject_tokens], generated_subject_tokens) # Pass tokenized input\n",
        "\n",
        "    # SACREBLEU - Use import sacrebleu directly\n",
        "    sacre_bleu_score = sacrebleu.corpus_bleu([generated_subject], [[true_subject]]).score\n",
        "\n",
        "    return rougeL, meteor, sacre_bleu_score # Return the score, not the module\n",
        "\n",
        "small_test_df['rougeL'], small_test_df['meteor'], small_test_df['sacrebleu'] = zip(*small_test_df.apply(\n",
        "    lambda row: evaluate_metrics(row['subject'], row['generated_subject_line']), axis=1))"
      ],
      "metadata": {
        "id": "fjUdAhycdLvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_test_df"
      ],
      "metadata": {
        "id": "E4bo2fd6NQQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")"
      ],
      "metadata": {
        "id": "tAUYMLeiWoQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_prompt = 'Generate the subject line for the following email.\\n\\nEmail:'\n",
        "end_prompt = '\\nSubject:\\n'\n",
        "start_prompt + email + end_prompt\n",
        "print(start_prompt)\n",
        "print(email)\n",
        "print(end_prompt)"
      ],
      "metadata": {
        "id": "hcU_iws1LLSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization for FLAN-T5 model\n",
        "def flan_t5_base_tokenize_function(example):\n",
        "    start_prompt = 'Generate the subject line for the following email.\\n\\nEmail:'\n",
        "    end_prompt = '\\nSubject:\\n'\n",
        "    prompt = [start_prompt + email + end_prompt for email in example[\"body\"]]\n",
        "    example['input_ids'] = flan_t5_base_tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = flan_t5_base_tokenizer(example[\"subject\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    return example\n",
        "\n",
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "tokenized_train_datasets = train_dataset.map(flan_t5_base_tokenize_function, batched=True)\n",
        "tokenized_test_datasets = test_dataset.map(flan_t5_base_tokenize_function, batched=True)\n"
      ],
      "metadata": {
        "id": "PNZhgan9fJ6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_train_datasets = tokenized_train_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)\n",
        "# tokenized_test_datasets = tokenized_test_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"
      ],
      "metadata": {
        "id": "EkFTC1Mvr81h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_datasets, tokenized_test_datasets"
      ],
      "metadata": {
        "id": "lV8NjE0YrWaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FLAN-T5 BASE - Fine-Tune the Model with the Preprocessed Tokenised Dataset utiliing the built-in Hugging Face Trainer class. Then compare it with reference to the original model.**\n",
        "\n",
        "flan_t5_base_original_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base', torch_dtype=torch.bfloat16)\n",
        "flan_t5_base_tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')"
      ],
      "metadata": {
        "id": "Q0tc44JYPNW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    start_prompt = 'Generate the subject line for the following email.\\n\\nEmail:'\n",
        "    end_prompt = '\\nSubject:\\n'\n",
        "    inputs = [start_prompt + email + end_prompt for email in examples['email_body']]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding='max_length')\n",
        "\n",
        "    labels = tokenizer(examples['subject'], max_length=50, truncation=True, padding='max_length')\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset.column_names)\n"
      ],
      "metadata": {
        "id": "H1GVZxyPU56L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Tokenization\n",
        "# def preprocess_data(examples):\n",
        "#     inputs = [\"generate subject line: \" + email for email in examples['cleaned_emails']]\n",
        "#     model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "#     with tokenizer.as_target_tokenizer():\n",
        "#         labels = tokenizer(examples['subject'], max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "#     return model_inputs\n",
        "\n",
        "# train_dataset = train_dataset.map(preprocess_data, batched=True)\n",
        "# test_dataset = test_dataset.map(preprocess_data, batched=True)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=flan_t5_base_original_model ,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_datasets,\n",
        "    eval_dataset=tokenized_test_datasets,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "RV5TsUrfR1zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLAN-T5 SMALL - Fine-Tune the Model with the Preprocessed Tokenised Dataset utiliing the built-in Hugging Face Trainer class. Then compare it with reference to the original model.\n",
        "\n",
        "flan_t5_small_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.bfloat16)\n",
        "flan_t5_small_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")"
      ],
      "metadata": {
        "id": "YrHuhrEfsmdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization for FLAN-T5 SMALL model\n",
        "def flan_t5_small_tokenize_function(example):\n",
        "    start_prompt = 'Generate the subject line for the following email.\\n\\nEmail:'\n",
        "    end_prompt = '\\nSubject:\\n'\n",
        "    prompt = [start_prompt + email + end_prompt for email in example[\"cleaned_emails\"]]\n",
        "    example['input_ids'] = flan_t5_small_tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = flan_t5_small_tokenizer(example[\"subject\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    return example\n",
        "\n",
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "tokenized_train_datasets = train_dataset.map(flan_t5_small_tokenize_function, batched=True)\n",
        "tokenized_test_datasets = test_dataset.map(flan_t5_small_tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "n15RWBkAXxzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Define Trainer\n",
        "trainer = Trainer(\n",
        "    model=flan_t5_small_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_datasets,\n",
        "    eval_dataset=tokenized_test_datasets,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "GjJMAmUcYSh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model checkpoint\n",
        "flan_t5_small_model.save_pretrained('./results/Flan_T5_small_model')\n",
        "flan_t5_small_tokenizer.save_pretrained('./results/Flan_T5_small_model')\n",
        "\n",
        "# Define and save the generation configuration\n",
        "generation_config = GenerationConfig(\n",
        "    early_stopping=True,\n",
        "    num_beams=4,\n",
        "    no_repeat_ngram_size=3,\n",
        "    forced_bos_token_id=0,\n",
        "    forced_eos_token_id=2\n",
        ")\n",
        "\n",
        "generation_config.save_pretrained('./results/Flan_T5_small_model')"
      ],
      "metadata": {
        "id": "CcOfhXaGdmyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AutoModelForSeq2SeqLM\n",
        "AutoTokenizer"
      ],
      "metadata": {
        "id": "tESux8htfc_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained Flan T5 Small fine tuned model\n",
        "flan_T5_small_model_directory = '/content/results/Flan_T5_small_model'\n",
        "flan_T5_small_tokenizer = AutoTokenizer.from_pretrained(flan_T5_small_model_directory)\n",
        "flan_T5_small_model_finetuned = AutoModelForSeq2SeqLM.from_pretrained(flan_T5_small_model_directory)"
      ],
      "metadata": {
        "id": "PM4itxVveS3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails_for_score = tokenized_test_datasets[0:10]['cleaned_emails']\n",
        "original_subjects = tokenized_test_datasets[0:10]['subject']"
      ],
      "metadata": {
        "id": "b9GGjgy6b0cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flan_T5small_subjects = []\n",
        "finetuned_flan_T5small_subjects = []\n",
        "\n",
        "for _, cleaned_emails in enumerate(emails_for_score):\n",
        "    prompt = f\"\"\"\n",
        "    Generate the subject line for the following email.\n",
        "\n",
        "    Email:\n",
        "    {email}\n",
        "\n",
        "    Subject:\n",
        "    \"\"\"\n",
        "    # Tokenize the input and move to the same device as the model\n",
        "    inputs = flan_t5_small_tokenizer(prompt, return_tensors='pt').to(flan_T5_small_model_finetuned.device) # Move inputs to the same device as the fine-tuned model\n",
        "\n",
        "    # Add the decoder_start_token_id to the generation configuration\n",
        "    generation_config = GenerationConfig(max_new_tokens=200,\n",
        "        decoder_start_token_id=flan_T5_small_tokenizer.bos_token_id if flan_T5_small_tokenizer.bos_token_id is not None else flan_T5_small_tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Generate subject using the original model\n",
        "    # Make sure flan_t5_small_model is on the same device as flan_T5_small_model_finetuned\n",
        "    flan_t5_small_model = flan_t5_small_model.to(flan_T5_small_model_finetuned.device)\n",
        "    original_model_outputs = flan_t5_small_model.generate(**inputs, generation_config=generation_config)\n",
        "    original_model_subject_output = flan_t5_small_tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    flan_T5small_subjects.append(original_model_subject_output)\n",
        "\n",
        "    # Generate subject using the finetuned model\n",
        "    trained_flan_t5_outputs = flan_T5_small_model_finetuned.generate(**inputs, generation_config=generation_config)\n",
        "    instruct_model_text_output = flan_T5_small_tokenizer.decode(trained_flan_t5_outputs[0], skip_special_tokens=True)\n",
        "    finetuned_flan_T5small_subjects.append(instruct_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(original_subjects, flan_T5small_subjects, finetuned_flan_T5small_subjects))\n",
        "\n",
        "Flan_T5_Small_Subjects_df = pd.DataFrame(zipped_summaries, columns = ['Original_subjects', 'Flan_T5s_subjects', 'Finetuned_Flan_T5s_subjects'])\n",
        "Flan_T5_Small_Subjects_df"
      ],
      "metadata": {
        "id": "LXGOGtXUbh5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "# from datasets import Dataset\n",
        "\n",
        "\n",
        "# # Initialize tokenizer and model\n",
        "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "# T5_model = T5ForConditionalGeneration.from_pretrained('t5-small')"
      ],
      "metadata": {
        "id": "exqW5Kv0mzyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "    start_prompt = 'Generate the subject line for the following email.\\n\\n'\n",
        "    end_prompt = '\\n\\Subject: '\n",
        "    prompt = [start_prompt + email + end_prompt for email in example[\"cleaned_emails\"]]\n",
        "    # Tokenize the input_ids - do not flatten\n",
        "    example['input_ids'] = [tokenizer(p, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids[0] for p in prompt]\n",
        "    # Tokenize the labels - do not flatten\n",
        "    example['labels'] = [tokenizer(s, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids[0] for s in example[\"subject\"]]\n",
        "\n",
        "    return example"
      ],
      "metadata": {
        "id": "aJmS7TCD4cQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output_dir = f'./email-Subject-training-{str(int(time.time()))}'\n",
        "\n",
        "# # Define training arguments\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=output_dir,\n",
        "#     learning_rate=1e-5,\n",
        "#     num_train_epochs=3,\n",
        "#     weight_decay=0.01,\n",
        "#     logging_steps=30,\n",
        "#     evaluation_strategy='epoch',\n",
        "#     per_device_train_batch_size=4,  # Reduced batch size\n",
        "#     # max_steps=1\n",
        "# )\n",
        "\n",
        "# # training_args = TrainingArguments(\n",
        "# #     output_dir='./results',\n",
        "# #     evaluation_strategy='epoch',\n",
        "# #     learning_rate=1e-5,\n",
        "# #     per_device_train_batch_size=4,\n",
        "# #     per_device_eval_batch_size=4,\n",
        "# #     num_train_epochs=3,\n",
        "# #     weight_decay=0.01,\n",
        "# # )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=flan_t5_base_original_model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=tokenized_train_datasets,\n",
        "#     eval_dataset=tokenized_test_datasets\n",
        "# )\n",
        "\n",
        "# trainer.train()"
      ],
      "metadata": {
        "id": "ymjhoRaoshwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Generate subject lines for the test set\n",
        "# def generate_subject_line(email_body):\n",
        "#     inputs = tokenizer(\"generate subject line: \" + email_body, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "#     # Move inputs to the same device as the model\n",
        "#     inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "#     outputs = model.generate(inputs.input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
        "#     return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# test_df['generated_subject_line'] = test_df['cleaned_emails'].apply(generate_subject_line)\n",
        "\n",
        "# Generate subject lines for the test set\n",
        "def generate_subject_line(email_body):\n",
        "    inputs = tokenizer(\"generate subject line: \" + email_body, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    # Move inputs to the same device as the model\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    # Access input_ids as a key in the dictionary\n",
        "    outputs = model.generate(inputs['input_ids'], max_length=128, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "test_df['generated_subject_line'] = test_df['cleaned_emails'].apply(generate_subject_line)"
      ],
      "metadata": {
        "id": "H00VaamVakII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **t5-small Evaluation**"
      ],
      "metadata": {
        "id": "cQ4bUC74cjcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "import sacrebleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)"
      ],
      "metadata": {
        "id": "XJ3D8o9yegTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the 'punkt' resource\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet') # Download WordNet\n",
        "\n",
        "from rouge_score import rouge_scorer\n",
        "import sacrebleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "\n",
        "# Evaluate the generated subject lines\n",
        "def evaluate_metrics(true_subject, generated_subject):\n",
        "    # Tokenize the input for METEOR\n",
        "    true_subject_tokens = nltk.word_tokenize(true_subject)\n",
        "    generated_subject_tokens = nltk.word_tokenize(generated_subject)\n",
        "\n",
        "    # ROUGE-L\n",
        "    rougeL = scorer.score(true_subject, generated_subject)['rougeL'].fmeasure\n",
        "\n",
        "    # METEOR\n",
        "    meteor = meteor_score([true_subject_tokens], generated_subject_tokens) # Pass tokenized input\n",
        "\n",
        "    # SACREBLEU - Use import sacrebleu directly\n",
        "    sacre_bleu_score = sacrebleu.corpus_bleu([generated_subject], [[true_subject]]).score\n",
        "\n",
        "    return rougeL, meteor, sacre_bleu_score # Return the score, not the module\n",
        "\n",
        "test_df['rougeL'], test_df['meteor'], test_df['sacrebleu'] = zip(*test_df.apply(\n",
        "    lambda row: evaluate_metrics(row['subject'], row['generated_subject_line']), axis=1))\n",
        "\n",
        "# Calculate average scores\n",
        "average_rougeL = test_df['rougeL'].mean()\n",
        "average_meteor = test_df['meteor'].mean()\n",
        "average_sacrebleu = test_df['sacrebleu'].mean() # Now you should be able to calculate the mean\n",
        "\n",
        "print(f'Average ROUGE-L: {average_rougeL:.4f}')\n",
        "print(f'Average METEOR: {average_meteor:.4f}')\n",
        "print(f'Average SACREBLEU: {average_sacrebleu:.4f}')"
      ],
      "metadata": {
        "id": "t5C7gSX3ceB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pretrained('facebook/bart-base')**"
      ],
      "metadata": {
        "id": "nP7-BBpHezyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "K5lsH75xikZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Convert DataFrame to Dataset\n",
        "# train_dataset = Dataset.from_pandas(train_df)\n",
        "# test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "facebook_bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "facebook_bart_base_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
      ],
      "metadata": {
        "id": "W_UUmQ-O5tso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"For Model : facebook_bart_base_model \\n\",print_number_of_trainable_model_parameters(facebook_bart_base_model))"
      ],
      "metadata": {
        "id": "HGVkLIIf52zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate the subject line for the following email.\n",
        "\n",
        "Email:\n",
        "{email}\n",
        "\n",
        "Subject:\n",
        "\"\"\"\n",
        "\n",
        "inputs = facebook_bart_tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "# Move input tensors to the same device as the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "inputs = {k: v.to(facebook_bart_base_model.device) for k, v in inputs.items()}\n",
        "\n",
        "outputs = facebook_bart_base_model.generate(inputs['input_ids'], max_length=128, num_beams=4, early_stopping=True)\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE ORIGINAL HUMAN ANNOTED SUBJECT LINE :\\n{subject}\\n')\n",
        "print(dash_line)\n",
        "print(f'FB BART MODEL GENERATION - ZERO SHOT SUBJECT LINE:\\n{output}')"
      ],
      "metadata": {
        "id": "3p1txC8YLwi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenization\n",
        "def Tokenization_preprocess_data(examples):\n",
        "    inputs = [prompt + email for email in examples['cleaned_emails']]\n",
        "    model_inputs = facebook_bart_tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Use facebook_bart_tokenizer as the target tokenizer\n",
        "    with facebook_bart_tokenizer.as_target_tokenizer():\n",
        "        labels = facebook_bart_tokenizer(examples['subject'], max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "train_dataset = train_dataset.map(Tokenization_preprocess_data, batched=True)\n",
        "test_dataset = test_dataset.map(Tokenization_preprocess_data, batched=True)\n",
        "\n",
        "# # Define training arguments\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir='./results',\n",
        "#     evaluation_strategy='epoch',\n",
        "#     learning_rate=2e-5,\n",
        "#     per_device_train_batch_size=4,\n",
        "#     per_device_eval_batch_size=4,\n",
        "#     num_train_epochs=3,\n",
        "#     weight_decay=0.01,\n",
        "# )\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',        # Directory to save the model checkpoints\n",
        "    evaluation_strategy='steps',\n",
        "    save_steps=500,               # Save checkpoint every 1000 steps\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=200,\n",
        ")\n",
        "\n",
        "# Define Trainer\n",
        "facebook_bart_base_model_trainer = Trainer(\n",
        "    model=facebook_bart_base_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "facebook_bart_base_model_trainer.train()\n"
      ],
      "metadata": {
        "id": "UHfFS01Feyu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model checkpoint\n",
        "facebook_bart_base_model.save_pretrained('./results/FB_Bart_model')\n",
        "facebook_bart_tokenizer.save_pretrained('./results/FB_Bart_model')\n",
        "\n",
        "# Define and save the generation configuration\n",
        "generation_config = GenerationConfig(\n",
        "    early_stopping=True,\n",
        "    num_beams=4,\n",
        "    no_repeat_ngram_size=3,\n",
        "    forced_bos_token_id=0,\n",
        "    forced_eos_token_id=2\n",
        ")\n",
        "\n",
        "generation_config.save_pretrained('./results/FB_Bart_model')"
      ],
      "metadata": {
        "id": "8Pj219LPCVmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "id": "wfBgXge85Fxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "logs_folder = '/content/logs'  # Adjust to your source folder\n",
        "logs_git_folder = './content/qM-AI-L/email-subject/model-tuning/logs'  # Adjust to your repository folder\n",
        "\n",
        "# Copy the folder\n",
        "shutil.copytree(logs_folder, logs_git_folder)"
      ],
      "metadata": {
        "id": "62ihDbDA_Dgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "results_folder = '/content/results'  # Adjust to your source folder\n",
        "results_git_folder = './content/qM-AI-L/email-subject/model-tuning/results'  # Adjust to your repository folder\n",
        "\n",
        "# Copy the folder\n",
        "shutil.copytree(results_folder, results_git_folder)"
      ],
      "metadata": {
        "id": "KA6-ZTV1AoJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change directory to the cloned repository\n",
        "os.chdir('./content/qM-AI-L')  # Adjust to your repository folder\n",
        "\n",
        "# Configure Git (only needed once)\n",
        "!git config --global user.email \"mlreddy3082@gmail.com\"\n",
        "!git config --global user.name \"Mlr9459\"\n",
        "\n",
        "# Add, commit, and push changes\n",
        "!git add /content/qM-AI-L/email-subject/\n",
        "!git commit -m \"Add training outputs: model checkpoints, tokenizer, and generation configuration\"\n",
        "!git push origin master"
      ],
      "metadata": {
        "id": "qdXDrq7SCPm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model Quantitatively (with ROUGE Metric)\n",
        "The ROUGE metric) helps quantify the validity of summarizations produced by models. It compares summarizations to a \"baseline\" summary which is usually created by a human. While not perfect, it does indicate the overall increase in summarization effectiveness that we have accomplished by fine-tuning.**"
      ],
      "metadata": {
        "id": "BhjyD6Wyzxhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_datasets, tokenized_test_datasets"
      ],
      "metadata": {
        "id": "lKqFN4OX1yaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_datasets[0:10]['cleaned_emails']"
      ],
      "metadata": {
        "id": "m1tWpGFv2EcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails_for_score = tokenized_test_datasets[0:10]['cleaned_emails']\n",
        "human_annoted_subjects = tokenized_test_datasets[0:10]['subject']\n"
      ],
      "metadata": {
        "id": "pqox7th015Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facebook_bart_tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "facebook_bart_base_model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')"
      ],
      "metadata": {
        "id": "W1-e0Dgg4s71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_directory = '/content/results/FB_Bart_model'\n",
        "facebook_bart_tokenizer_trained = BartTokenizer.from_pretrained(model_directory)\n",
        "facebook_bart_base_model_trained = BartForConditionalGeneration.from_pretrained(model_directory)"
      ],
      "metadata": {
        "id": "gXnio11hELAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facebook_bart_subjects = []\n",
        "trained_facebook_bart_subjects = []\n",
        "\n",
        "for _, email in enumerate(emails_for_score):\n",
        "    prompt = f\"\"\"\n",
        "    Generate the subject line for the following email.\n",
        "\n",
        "    Email:\n",
        "    {email}\n",
        "\n",
        "    Subject:\n",
        "    \"\"\"\n",
        "    # Tokenize the input and move to the same device as the model\n",
        "    inputs = facebook_bart_tokenizer(prompt, return_tensors='pt').to(facebook_bart_base_model.device)\n",
        "\n",
        "    # Add the decoder_start_token_id to the generation configuration\n",
        "    generation_config = GenerationConfig(\n",
        "    max_new_tokens=200,\n",
        "    decoder_start_token_id=facebook_bart_tokenizer.bos_token_id  # Add this line\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Generate subject using the original model\n",
        "    original_model_outputs = facebook_bart_base_model.generate(**inputs, generation_config=generation_config)\n",
        "    original_model_subject_output = facebook_bart_tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    facebook_bart_subjects.append(original_model_subject_output)\n",
        "\n",
        "    trained_facebook_bart_outputs = facebook_bart_base_model_trained.generate(**inputs, generation_config=generation_config)\n",
        "    instruct_model_text_output = facebook_bart_tokenizer_trained.decode(trained_facebook_bart_outputs[0], skip_special_tokens=True)\n",
        "    trained_facebook_bart_subjects.append(instruct_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_annoted_subjects, facebook_bart_subjects, trained_facebook_bart_subjects))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_annoted_subjects', 'facebook_bart_subjects', 'trained_facebook_bart_subjects'])\n",
        "df"
      ],
      "metadata": {
        "id": "Yy9Bz2uV1c-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score\n",
        "from rouge_score import rouge_scorer\n",
        "from rouge_score.scoring import BootstrapAggregator\n",
        "\n"
      ],
      "metadata": {
        "id": "eMHM2fPzsAxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ROUGE scores for each pair of prediction and reference\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "aggregator = BootstrapAggregator() # Initialize aggregator\n",
        "\n",
        "for prediction, reference in zip(facebook_bart_subjects, human_annoted_subjects[0:len(facebook_bart_subjects)]):\n",
        "    score = scorer.score(reference, prediction)\n",
        "    aggregator.add_scores(score) # Add scores to aggregator\n",
        "\n",
        "# Aggregate the scores\n",
        "original_model_results = aggregator.aggregate()\n",
        "\n",
        "print(original_model_results)"
      ],
      "metadata": {
        "id": "eAzGwd9qrS0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=facebook_bart_subjects,\n",
        "    references=human_annoted_subjects[0:len(facebook_bart_subjects)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=trained_facebook_bart_subjects,\n",
        "    references=human_annoted_subjects[0:len(trained_facebook_bart_subjects)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ],
      "metadata": {
        "id": "4N2v_M6SJUBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model locally\n",
        "model_save_path = \"./facebook_bart_base\"\n",
        "facebook_bart_base_model.save_pretrained(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {model_save_path}\")"
      ],
      "metadata": {
        "id": "WCpjkEa9rWxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate subject lines for the test set\n",
        "def generate_subject_line(email_body):\n",
        "    inputs = tokenizer(\"generate subject line: \" + email_body, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    # Move inputs to the GPU if available\n",
        "    inputs = {k: v.to(facebook_bart_base_model.device) for k, v in inputs.items()}\n",
        "    # Access input_ids from the dictionary\n",
        "    outputs = facebook_bart_base_model.generate(inputs['input_ids'], max_length=128, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "test_df['generated_subject_line'] = test_df['body'].apply(generate_subject_line)"
      ],
      "metadata": {
        "id": "HM0tVaa5i8n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "n5PT2dfT2OEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "from rouge_score import rouge_scorer\n",
        "import sacrebleu\n",
        "from nltk.translate.meteor_score import meteor_score"
      ],
      "metadata": {
        "id": "T6KRD7Oo2Muk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "\n",
        "# Evaluate the generated subject lines\n",
        "def evaluate_metrics(true_subject, generated_subject):\n",
        "    # Tokenize the input for METEOR\n",
        "    true_subject_tokens = nltk.word_tokenize(true_subject)\n",
        "    generated_subject_tokens = nltk.word_tokenize(generated_subject)\n",
        "\n",
        "    # ROUGE-L\n",
        "    rougeL = scorer.score(true_subject, generated_subject)['rougeL'].fmeasure\n",
        "\n",
        "    # METEOR\n",
        "    meteor = meteor_score([true_subject_tokens], generated_subject_tokens) # Pass tokenized input\n",
        "\n",
        "    # SACREBLEU - Use import sacrebleu directly\n",
        "    sacre_bleu_score = sacrebleu.corpus_bleu([generated_subject], [[true_subject]]).score\n",
        "\n",
        "    return rougeL, meteor, sacre_bleu_score # Return the score, not the module\n",
        "\n",
        "test_df['rougeL'], test_df['meteor'], test_df['sacrebleu'] = zip(*test_df.apply(\n",
        "    lambda row: evaluate_metrics(row['subject'], row['generated_subject_line']), axis=1))"
      ],
      "metadata": {
        "id": "g5swqKxsfrQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate average scores\n",
        "average_rougeL = test_df['rougeL'].mean()\n",
        "average_meteor = test_df['meteor'].mean()\n",
        "average_sacrebleu = test_df['sacrebleu'].mean() # Now you should be able to calculate the mean\n",
        "\n",
        "print(f'Average facebook_bart_base_model ROUGE-L: {average_rougeL:.4f}')\n",
        "print(f'Average facebook_bart_base_model METEOR: {average_meteor:.4f}')\n",
        "print(f'Average facebook_bart_base_model SACREBLEU: {average_sacrebleu:.4f}')"
      ],
      "metadata": {
        "id": "TcCHg_OU29ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Replace 'directory_name' with the name of your directory\n",
        "shutil.make_archive('/content/facebook_bart_base_model', 'zip', 'facebook_bart_base_model')"
      ],
      "metadata": {
        "id": "Lzt-7qci4Niq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files.download('facebook_bart_base_model.zip')"
      ],
      "metadata": {
        "id": "pY7QEHAw4bsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **t5-base**"
      ],
      "metadata": {
        "id": "Dx76AiWz5CEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tokenizer and model t5-base\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n"
      ],
      "metadata": {
        "id": "qlr5gRXjGGw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(pivot_df)"
      ],
      "metadata": {
        "id": "zd2OYT0bXhMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "_dQE0OytX7D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(pivot_df):\n",
        "    inputs = pivot_df['cleaned_emails']\n",
        "    targets = pivot_df['subject']\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "j2MxJu3bGWxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "id": "K0aZkei_T0V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Replace 'directory_name' with the name of your directory\n",
        "# shutil.make_archive('/content/fine_tuned_t5', 'zip', 'fine_tuned_t5')\n",
        "\n",
        "# Download the zipped directory\n"
      ],
      "metadata": {
        "id": "uGocveE7q2_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.make_archive('/content/results', 'zip', 'FB_Bart_model_results')\n",
        "shutil.make_archive('/content/logs', 'zip', 'FB_Bart_model_logs')\n"
      ],
      "metadata": {
        "id": "eT_AJo9PEjxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files.download('fine_tuned_t5.zip')"
      ],
      "metadata": {
        "id": "ZO2hx72nrVx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "BDnsANB7Iz3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_dataset['attention_mask']\n",
        "# tokenized_dataset['input_ids']"
      ],
      "metadata": {
        "id": "6Mo5GbMDH8Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "# Data collator for padding\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
      ],
      "metadata": {
        "id": "0KMgDPdkU753"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=3,\n",
        "    # predict_with_generate=True,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "19V3PPTgVBQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('fine_tuned_t5')\n",
        "tokenizer.save_pretrained('fine_tuned_t5')"
      ],
      "metadata": {
        "id": "uvY_nd2_bise"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available. \\nUsing GPU\")\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"GPU is not available. \\nUsing CPU\")\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "9shJp4Spb3Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text):\n",
        "    inputs = tokenizer.encode_plus(text, return_tensors='pt', max_length=512, truncation=True)\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "    summary_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=150, num_beams=2, repetition_penalty=2.5, length_penalty=1.0, early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n"
      ],
      "metadata": {
        "id": "ohAtd3YQbn1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example inference\n",
        "example_text = pivot_df['body'][3]\n",
        "print(\"Email Body:\", example_text)\n",
        "print(\"\\n\\n Generated Subject:\", generate_summary(example_text))\n",
        "print(\"\\n\\n Actual Subject:\", pivot_df['subject'][3])"
      ],
      "metadata": {
        "id": "V_MzfdBqcJZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "import sacrebleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
        "\n",
        "# Evaluate the generated subject lines\n",
        "def evaluate_metrics(true_subject, generated_subject):\n",
        "    # ROUGE-L\n",
        "    rougeL = scorer.score(true_subject, generated_subject)['rougeL'].fmeasure\n",
        "\n",
        "    # METEOR\n",
        "    meteor = meteor_score([true_subject], generated_subject)\n",
        "\n",
        "    # SACREBLEU\n",
        "    sacre_bleu = sacrebleu.corpus_bleu([generated_subject], [[true_subject]]).score\n",
        "\n",
        "    return rougeL, meteor, sacre_bleu\n",
        "\n",
        "test_df['rougeL'], test_df['meteor'], test_df['sacrebleu'] = zip(*test_df.apply(\n",
        "    lambda row: evaluate_metrics(row['subject_line'], row['generated_subject_line']), axis=1))\n",
        "\n",
        "# Calculate average scores\n",
        "average_rougeL = test_df['rougeL'].mean()\n",
        "average_meteor = test_df['meteor'].mean()\n",
        "average_sacrebleu = test_df['sacrebleu'].mean()\n",
        "\n",
        "print(f'Average ROUGE-L: {average_rougeL:.4f}')\n",
        "print(f'Average METEOR: {average_meteor:.4f}')\n",
        "print(f'Average SACREBLEU: {average_sacrebleu:.4f}')"
      ],
      "metadata": {
        "id": "UvJijyqfN5k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_sentences(text):\n",
        "  \"\"\"\n",
        "  This function extracts sentences from text without introducing control characters.\n",
        "\n",
        "  Args:\n",
        "      text (str): The text to be processed.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of extracted sentences.\n",
        "  \"\"\"\n",
        "  # Split text based on sentence boundaries (adjust pattern as needed)\n",
        "  sentences = re.split(r\"(?<!\\w)\\.(?!\\w)\", text)\n",
        "\n",
        "  # Remove empty elements and leading/trailing whitespace\n",
        "  sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "  return sentences\n",
        "\n",
        "# Example usage\n",
        "text = \"This is an example text. It contains multiple sentences.  \\nThere are also newlines and extra spaces.\"\n",
        "extracted_sentences = extract_sentences(pivot_df['body'][0])\n",
        "print(extracted_sentences)\n"
      ],
      "metadata": {
        "id": "R_UuPM3bLEEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df['body'][0]"
      ],
      "metadata": {
        "id": "gW-fbCCleshA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "summary = summarizer(pivot_df['body'][0], max_length=15, min_length=2, do_sample=False)\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "id": "8hmYeCH2flFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df['body'][0]"
      ],
      "metadata": {
        "id": "QSg88TJak4t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Chirayu/subject-generator-t5-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Chirayu/subject-generator-t5-base\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "def get_subject(content, num_beams=5,max_length=512, repetition_penalty=2.5, length_penalty=1, early_stopping=True,top_p=.95, top_k=50, num_return_sequences=3):\n",
        "\n",
        "  text =  \"title: \" + content + \" </s>\"\n",
        "\n",
        "  input_ids = tokenizer.encode(\n",
        "    text, return_tensors=\"pt\", add_special_tokens=True\n",
        "  )\n",
        "\n",
        "  input_ids = input_ids.to(device)\n",
        "  generated_ids = model.generate(\n",
        "      input_ids=input_ids,\n",
        "\n",
        "      num_beams=num_beams,\n",
        "      max_length=max_length,\n",
        "      repetition_penalty=repetition_penalty,\n",
        "      length_penalty=length_penalty,\n",
        "      early_stopping=early_stopping,\n",
        "      top_p=top_p,\n",
        "      top_k=top_k,\n",
        "      num_return_sequences=num_return_sequences,\n",
        "  )\n",
        "  subjects = [tokenizer.decode(generated_id,skip_special_tokens=True,clean_up_tokenization_spaces=True,) for generated_id in generated_ids]\n",
        "  return subjects"
      ],
      "metadata": {
        "id": "eI-YnG00leqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = get_subject(pivot_df['body'][0])\n",
        "x"
      ],
      "metadata": {
        "id": "JhMrjNf3mKOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df['body'][0]"
      ],
      "metadata": {
        "id": "fTcDIbDHq1wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df['body'][1]"
      ],
      "metadata": {
        "id": "X3-wKWGkmgXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap"
      ],
      "metadata": {
        "id": "XOWH5k3TjZqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_summarizer(email_text):\n",
        "\n",
        "    model_name = \"facebook/bart-large-cnn\"\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    inputs = tokenizer.encode(\"summarize: \" + email_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=100, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    formatted_summary = \"\\n\".join(textwrap.wrap(summary, width=80))\n",
        "    return formatted_summary\n",
        "\n",
        "summary = text_summarizer(pivot_df['body'][0])\n",
        "summary"
      ],
      "metadata": {
        "id": "Y85goaEkcOYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sentences(text):\n",
        "    \"\"\"\n",
        "    Extract sentences from the text and remove newline characters.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The text to process.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of sentences without newline characters.\n",
        "    \"\"\"\n",
        "    # Replace newline characters with spaces\n",
        "    text = text.replace('\\n', '')\n",
        "    text = text.replace('!', '.').replace('?', '.').replace(';', '.')\n",
        "\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"Hello, world!\\nThis is a test.\\nLet's replace, commas, and newlines.\"\n",
        "sentences = extract_sentences(sample_text)\n",
        "for sentence in sentences:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "id": "zGazV9EgQkxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = text_summarizer(pivot_df['body'][0])\n",
        "summary"
      ],
      "metadata": {
        "id": "jezqQnA9Lck-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df['body'][0]"
      ],
      "metadata": {
        "id": "7ZrJIfk2MFn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email_len = [len(pivot_df['dialogue'].split()) for x in samsum['train']]\n",
        "sub_len = [len(pivot_df['summary'].split()) for x in samsum['train']]\n",
        "\n",
        "dialogue_len = [len(x['dialogue'].split()) for x in samsum['train']]\n",
        "summary_len = [len(x['summary'].split()) for x in samsum['train']]\n",
        "\n"
      ],
      "metadata": {
        "id": "_AM_aMgKSjST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "describe_df(pivot_df)"
      ],
      "metadata": {
        "id": "0N8EfTwkRqF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_rows"
      ],
      "metadata": {
        "id": "FrRN8if0dyTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.preprocessing import Tokenizer, Lowercaser, PunctuationRemover, StopwordRemover\n",
        "from langchain.stemming import Stemmer\n",
        "from langchain import Pipeline"
      ],
      "metadata": {
        "id": "oKUEMAee8aSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(email_docs)*3"
      ],
      "metadata": {
        "id": "REA79efkSNQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails_df['content'][0]"
      ],
      "metadata": {
        "id": "pwhf-gfhMfWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails_df['source'][0]"
      ],
      "metadata": {
        "id": "FLk0SU2hTPr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_file_name(emails_df['source'][0])"
      ],
      "metadata": {
        "id": "XTKL_ao_T6jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8h-_DelG2pb9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30d4a769c5544445bc13b613ba4cdee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_385784146b014ea2821e9c9a3320ba10",
              "IPY_MODEL_211e0379921d43458478b337eb094fc8",
              "IPY_MODEL_d3570989cfbf4fce801c7447d73d0bfc"
            ],
            "layout": "IPY_MODEL_277b89aaf7e54b4e98cc45bc462cb785"
          }
        },
        "385784146b014ea2821e9c9a3320ba10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de7042c773dd40b9bf418c1eb3819d10",
            "placeholder": "​",
            "style": "IPY_MODEL_cca7d9baea174787b47cfdcca7917605",
            "value": "Map: 100%"
          }
        },
        "211e0379921d43458478b337eb094fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b05f2f54dc864de4be3074c4f9ad7d36",
            "max": 4619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f77b0189f69a46e8bead1f0d5147f08e",
            "value": 4619
          }
        },
        "d3570989cfbf4fce801c7447d73d0bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df4493809ee46a39606e261e0307d86",
            "placeholder": "​",
            "style": "IPY_MODEL_eddfa8b95bef4f2a90eabbbf5beb44f3",
            "value": " 4619/4619 [00:04&lt;00:00, 963.48 examples/s]"
          }
        },
        "277b89aaf7e54b4e98cc45bc462cb785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de7042c773dd40b9bf418c1eb3819d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca7d9baea174787b47cfdcca7917605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b05f2f54dc864de4be3074c4f9ad7d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77b0189f69a46e8bead1f0d5147f08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1df4493809ee46a39606e261e0307d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eddfa8b95bef4f2a90eabbbf5beb44f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "732f0b70b0ef49499d6561a7bb6ad501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45d1b5f21e934f23b9554187e87ea044",
              "IPY_MODEL_8dbee6ae34fa42c6bf4aac2b23db1b85",
              "IPY_MODEL_ebe80713abc940c5b809f797efc4a5a2"
            ],
            "layout": "IPY_MODEL_a36c3b821f704f129925652a6b3fd900"
          }
        },
        "45d1b5f21e934f23b9554187e87ea044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8528113119e4b97834bfc4773b727a1",
            "placeholder": "​",
            "style": "IPY_MODEL_3b70fd8ff0cc4555863715125a082c95",
            "value": "Map: 100%"
          }
        },
        "8dbee6ae34fa42c6bf4aac2b23db1b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd3b8972df24895812a9e97b7c8f934",
            "max": 1155,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca4c6eb0606e43d5bb3122fe53381e45",
            "value": 1155
          }
        },
        "ebe80713abc940c5b809f797efc4a5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9191abe97b04938840b2e768a724b41",
            "placeholder": "​",
            "style": "IPY_MODEL_6fc0bea417b14f2d9468427a0b08cc2a",
            "value": " 1155/1155 [00:01&lt;00:00, 683.30 examples/s]"
          }
        },
        "a36c3b821f704f129925652a6b3fd900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8528113119e4b97834bfc4773b727a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b70fd8ff0cc4555863715125a082c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fd3b8972df24895812a9e97b7c8f934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca4c6eb0606e43d5bb3122fe53381e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9191abe97b04938840b2e768a724b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc0bea417b14f2d9468427a0b08cc2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efd9774844034197a1642d921de0f1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbb7558ef2ce42eabad4554577810d64",
              "IPY_MODEL_60bafab258324300bb39c46cd9f37f98",
              "IPY_MODEL_b2de8e70619d46c0800a489ec118ff60"
            ],
            "layout": "IPY_MODEL_727fa3ec29b24f0689c79aba203f6ca2"
          }
        },
        "bbb7558ef2ce42eabad4554577810d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12125b0a2d114f7f9bbca8b9684dd61c",
            "placeholder": "​",
            "style": "IPY_MODEL_7db63ff48a8543b7aa0a16fadd2a2f34",
            "value": "config.json: 100%"
          }
        },
        "60bafab258324300bb39c46cd9f37f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30da70ee1acf48e08b12d65df2bc5614",
            "max": 1401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abb5ee6bb64246b8b71bc120dbaa5794",
            "value": 1401
          }
        },
        "b2de8e70619d46c0800a489ec118ff60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9cdf21d4ceb4900a62e49389da304b3",
            "placeholder": "​",
            "style": "IPY_MODEL_796fb397a4ea40b880e2d667ecbe4843",
            "value": " 1.40k/1.40k [00:00&lt;00:00, 97.8kB/s]"
          }
        },
        "727fa3ec29b24f0689c79aba203f6ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12125b0a2d114f7f9bbca8b9684dd61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db63ff48a8543b7aa0a16fadd2a2f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30da70ee1acf48e08b12d65df2bc5614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abb5ee6bb64246b8b71bc120dbaa5794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9cdf21d4ceb4900a62e49389da304b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796fb397a4ea40b880e2d667ecbe4843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02fa1934432648c8b5f9537e6fa2a49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c3b8da68ab04423a5c0dc2f9642292f",
              "IPY_MODEL_8e90df0c460348a6b19c463eeef26879",
              "IPY_MODEL_40f6253703cf432cbfe5659ce422f7e1"
            ],
            "layout": "IPY_MODEL_9e58512151d34d27be43a294b105ed87"
          }
        },
        "9c3b8da68ab04423a5c0dc2f9642292f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10ddf730a60a4d4bbe0da1b59aed7560",
            "placeholder": "​",
            "style": "IPY_MODEL_289cb1838aa64612808451f6bdf25f81",
            "value": "model.safetensors: 100%"
          }
        },
        "8e90df0c460348a6b19c463eeef26879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bbd2eb1d40c4218b7997982c10e5a1d",
            "max": 307867048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2cb2bc5d32b444b80f6334fd879ca79",
            "value": 307867048
          }
        },
        "40f6253703cf432cbfe5659ce422f7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c52aad7389b34312aa1d0497824893dd",
            "placeholder": "​",
            "style": "IPY_MODEL_28f98c9b011c4da49ba3c7b42068bb8f",
            "value": " 308M/308M [00:06&lt;00:00, 51.3MB/s]"
          }
        },
        "9e58512151d34d27be43a294b105ed87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ddf730a60a4d4bbe0da1b59aed7560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289cb1838aa64612808451f6bdf25f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bbd2eb1d40c4218b7997982c10e5a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2cb2bc5d32b444b80f6334fd879ca79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c52aad7389b34312aa1d0497824893dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f98c9b011c4da49ba3c7b42068bb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f18d8b482eb84f4a97dc182ab679444e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3961a5f4369446d881055b72c282b8f2",
              "IPY_MODEL_9a465303403249d2b8627ba98d4a3499",
              "IPY_MODEL_43aa877170bb44c8846e62a871c3de01"
            ],
            "layout": "IPY_MODEL_f12f706f8a8645dc985a0e08faed2c02"
          }
        },
        "3961a5f4369446d881055b72c282b8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edaed9d68f4848e796218299bb5f8ceb",
            "placeholder": "​",
            "style": "IPY_MODEL_98672a88021a4557b392607e085ba8fc",
            "value": "generation_config.json: 100%"
          }
        },
        "9a465303403249d2b8627ba98d4a3499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1e174126b3476d8e7d672684b5357a",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_596a91deb36d4b859d28d6ab1e0dc0c6",
            "value": 147
          }
        },
        "43aa877170bb44c8846e62a871c3de01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c9a09f9d6c24e78960ef681a9bb7479",
            "placeholder": "​",
            "style": "IPY_MODEL_331ae92ef9924d84811a56003c1090f1",
            "value": " 147/147 [00:00&lt;00:00, 8.07kB/s]"
          }
        },
        "f12f706f8a8645dc985a0e08faed2c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edaed9d68f4848e796218299bb5f8ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98672a88021a4557b392607e085ba8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec1e174126b3476d8e7d672684b5357a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596a91deb36d4b859d28d6ab1e0dc0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c9a09f9d6c24e78960ef681a9bb7479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331ae92ef9924d84811a56003c1090f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eb20e66ffd041b0913ca612da305c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4c468e128c947fdbbc96e5696b0f1e4",
              "IPY_MODEL_c9c1492eaf904461b0e554a01259b167",
              "IPY_MODEL_1f6ceabfaf2f43e1a3890e1bc41f90bd"
            ],
            "layout": "IPY_MODEL_dab896cb177a487c97b74d5798253b97"
          }
        },
        "b4c468e128c947fdbbc96e5696b0f1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdaf84f879f64c34a61da5992336ac03",
            "placeholder": "​",
            "style": "IPY_MODEL_97ab798a668f4f769408c82aefd3e5fb",
            "value": "Map: 100%"
          }
        },
        "c9c1492eaf904461b0e554a01259b167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a2db8634724944b675f6b1068684fb",
            "max": 4619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_577d0cd38dec475ebdb45ad1e197b86f",
            "value": 4619
          }
        },
        "1f6ceabfaf2f43e1a3890e1bc41f90bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3230f592e16b4c279ee4e92dc9bd3490",
            "placeholder": "​",
            "style": "IPY_MODEL_9d73a99b457d4252b5de5062d216d0e0",
            "value": " 4619/4619 [00:05&lt;00:00, 849.73 examples/s]"
          }
        },
        "dab896cb177a487c97b74d5798253b97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdaf84f879f64c34a61da5992336ac03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ab798a668f4f769408c82aefd3e5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49a2db8634724944b675f6b1068684fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577d0cd38dec475ebdb45ad1e197b86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3230f592e16b4c279ee4e92dc9bd3490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d73a99b457d4252b5de5062d216d0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e47ed7f81ed4e1e82335b4b3bda2247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5809067f9e14175a08f8464be80d653",
              "IPY_MODEL_5fe96090dae54689809dbe8b0ff0a0ca",
              "IPY_MODEL_89e0141f4a884a0e8e03b4b2bbed1f27"
            ],
            "layout": "IPY_MODEL_4054cd2fbe484e27a70648bd5baffd6d"
          }
        },
        "f5809067f9e14175a08f8464be80d653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e544eec96f994bfebbdde3f41f720c31",
            "placeholder": "​",
            "style": "IPY_MODEL_c8158ecaa9b340eeb855e48e7e552955",
            "value": "Map: 100%"
          }
        },
        "5fe96090dae54689809dbe8b0ff0a0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3abddc18f024dc39f65444c47c7f278",
            "max": 14436,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7906edcf5f642babea0d43876f400bb",
            "value": 14436
          }
        },
        "89e0141f4a884a0e8e03b4b2bbed1f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90a098b7e47c4213b80241b9dbcb11fd",
            "placeholder": "​",
            "style": "IPY_MODEL_00995755b0d44067a89e0120321dbf3b",
            "value": " 14436/14436 [00:14&lt;00:00, 1243.51 examples/s]"
          }
        },
        "4054cd2fbe484e27a70648bd5baffd6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e544eec96f994bfebbdde3f41f720c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8158ecaa9b340eeb855e48e7e552955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3abddc18f024dc39f65444c47c7f278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7906edcf5f642babea0d43876f400bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90a098b7e47c4213b80241b9dbcb11fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00995755b0d44067a89e0120321dbf3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}